---
title: "Enhancing Sound, Music, and Movement Computing with DifferentiableÂ DSP"
collection: talks
type: "Talk"
permalink: /talks/2022-06-09-SMC22
venue: "Sound and Music Computing Conference (SMC'22), St. Ethienne, France"
date: 2022-06-09
location: "Online"
---
Impact of Differentiable Digital Signal Processing (DDSP) on the recent work at the [Multisensory Experience Lab](https://melcph.create.aau.dk/) Hints: We can deploy DDSP-based real-time plugins fast because 

1. we started the work about 25 years ago :-) 
2. we are implementing the principles of MLOPs. 

Do these, and the future will be yours :-) 

In the [Multisensory Experience Lab](https://melcph.create.aau.dk/), we traditionally rely on physics-based audio and haptic models for multisensory processing. Currently we focus on physics-based deep learning and differentiable DSP for constructing real-time models or estimating the model parameters. More recently we realized the importance of [ðŸš€Â Putting these ML models in Production](https://madewithml.com/courses/putting-ml-in-production/) as real-time plugins. The talk compares this approach to what was used two decades ago with shallow-learning *models*, self-recoreded or synthetic *data*, and *self-written code and frameworks*- 

[Watch the talk @Youtube](https://youtu.be/Kr_807NNYVU?t=513)

[comment]: # <iframe width="560" height="315" src="https://www.youtube.com/embed/Kr_807NNYVU?t=513" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
