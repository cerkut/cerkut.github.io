---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

% ADDS bibtex_show and preview
@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

@article{Jylhae-2011,
  author =	 {Jylh{\"a}, Antti and Ekman, Inger and Erkut, Cumhur and Tahiro{\u{g}}lu, Koray},
  title =	 {Design and Evaluation of Rhythmic Interaction With an Interactive Tutoring System},
  journal =	 {Computer Music Journal},
  volume =	 35,
  number =	 2,
  pages =	 {36--48},
  year =	 2011,
  doi =		 {10.1162/comj\_a\_00055},
  url =		 {http://www.mitpressjournals.org/doi/abs/10.1162/COMJ\_a\_00055},
}


@inproceedings{Cem97,
  year =	 1997,
  keywords =	 {calib,modeling,physical,schema},
  author =	 {Cemgil, Ali Taylan and Erkut, Cumhur},
  title =	 {Calibration of physical models using artificial neural networks with application to plucked string instruments},
  pages =	 {213--218},
  booktitle =	 {Proc. Intl. Symp. Musical Acoustics},
  address =	 {Edinburgh, Scotland, UK},
  url =		 {https://www.researchgate.net/publication/2543549},
  pdf =		 {https://www.researchgate.net/publication/2543549},
  google_scholar_id ={hAKLGSx4MfsJ},
}



@article{Hoeoek-2018,
  author =	 {H{\"o}{\"o}k, Kristina and Caramiaux, Baptiste and Erkut, Cumhur and Forlizzi, Jodi and Hajinejad, Nassrin and Haller, Michael and Hummels, Caroline and Isbister, Katherine and Jonsson, Martin and Khut, George and Loke, Lian and Lottridge, Danielle and Marti, Patrizia and Melcer, Edward and M{\"u}ller, Florian and Petersen, Marianne and Schiphorst, Thecla and Segura, Elena and St{\aa}hl, Anna and Svan{\ae}s, Dag and Tholander, Jakob and Tobiasson, Helena},
  title =	 {Embracing First-Person Perspectives in Soma-Based Design},
  journal =	 {Informatics},
  volume =	 5,
  number =	 1,
  pages =	 8,
  year =	 2018,
  doi =		 {10.3390/informatics5010008},
  url =		 {http://www.mdpi.com/2227-9709/5/1/8},
  abstract =	 {{A set of prominent designers embarked on a research journey to explore aesthetics in movement-based design. Here we unpack one of the design sensitivities unique to our practice: a strong first person perspective-where the movements, somatics and aesthetic sensibilities of the designer, design researcher and user are at the forefront. We present an annotated portfolio of design exemplars and a brief introduction to some of the design methods and theory we use, together substantiating and explaining the first-person perspective. At the same time, we show how this felt dimension, despite its subjective nature, is what provides rigor and structure to our design research. Our aim is to assist researchers in soma-based design and designers wanting to consider the multiple facets when designing for the aesthetics of movement. The applications span a large field of designs, including slow introspective, contemplative interactions, arts, dance, health applications, games, work applications and many others.}},
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}


@inproceedings{Olajec07:Finsig,
  year =	 {2007},
  rating =	 {0},
  keywords =	 {audience,audio,clapping,classification,feature,genetic},
  author =	 {Olajec, Jan and Erkut, Cumhur and Jarina, Roman},
  title =	 {{GA-based feature selection for synchronous and asynchronous applause detection}},
  url =		 {http://kt.utc.sk/\textbackslashtextasciitildeolajec/publications/\%5B10\%5D\_-\_FinSig\_2007.pdf},
  urldate =	 {0},
  series =	 {FINNSIG '07},
  note =	 {\#audience \#audio indexing \#clapping \#classification \#feature selection \#genetic algorithm CD-ROM proceedings},
  month =	 {08}
}
@inproceedings{Erkut:2013wx,
  year =	 {2013},
  rating =	 {0},
  author =	 {Erkut, Cumhur and Bednarik, Roman and Mäkelä, Susanne and Kleimola, Jari},
  title =	 {{Apps for Me, Too: Gaze and Natural Interaction Applications for Varying Cognitive Strengths on a Multi-touch Table Network}},
  urldate =	 {0},
  series =	 {Conf. Human Factors in Computing Systems},
  keywords =	 {},
  month =	 {04}
}
@techreport{Erkut:2011vq, 
year = {2011}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{COST-PSD-Scientific-Report}}, 
keywords = {}, 
month = {04}
}
@inproceedings{Erkut02:ISMA, 
year = {2002}, 
rating = {0}, 
keywords = {alma,differences,finite,kw-converter,modeling,physical,Sound}, 
author = {Erkut, Cumhur}, 
title = {{Finite difference method vs. digital waveguide method in string instrument modeling and synthesis}}, 
abstract = {{Abstract The one-dimensional digital waveguides, combined with the commuted synthesis method, allow modeling and high-quality synthesis of plucked string instrument tones in a very efficient manner. However, the increasing computational power of the modern ...}}, 
urldate = {0}, 
note = {\#alma \#differences \#finite \#kw-converter \#modeling \#physical \#physical modeling \#Sound Synthesis}
}
@inproceedings{Erkut:2017ke, 
year = {2017}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{Rhythmic interaction in VR: interplay between sound design and editing}}, 
isbn = {978-1-5386-0459-5}, 
doi = {10.1109/sive.2017.7901611}, 
abstract = {{Cinematic virtual reality is a new and relatively unexplored area in academia. While research in guiding the spectator's attention in this new medium has been conducted for some time, a focus on editing in conjunction with spectator orientation is only currently emerging. In this paper, we consider rhythm as an important element in guiding attention. Starting with the possibility of applying some concepts from rhythm-action games to virtual reality, we discuss specific film editing and rhythmic interaction design techniques that can be used in cinematic virtual reality. We provide a background in rhythm perception, and complement it with applications in traditional editing. Through the notion of multimodal listening we provide guidelines that can be used in rhythmic and sonic interaction design in VR.}}, 
urldate = {0}, 
series = {IEEE VR Workshop on Sonic Interactions for Virtual Environments (SIVE)}, 
note = {Bump for RAction}, 
keywords = {}
}
@article{citeulike:970245, 
year = {2003}, 
rating = {0}, 
keywords = {physical}, 
title = {{Compilation of unified physical models for efficient sound synthesis}}, 
author = {Erkut, Cumhur and Savioja, Lauri}, 
journal = {International Conference on Acoustics, Speech and Signal Processing (ICASSP'03)}, 
issn = {1520-6149}, 
doi = {10.1109/icassp.2003.1199999}, 
abstract = {{This paper describes a systematic approach to specification and compilation of different physical modeling schemes particularly for sound synthesis studies. First we formulate theoretically a unified way of constructing physical interaction models wh...}}, 
pages = {V 433--6 vol.5}, 
volume = {5}, 
language = {English}, 
note = {\#physical modeling}
}
@article{Valimaki:2003tv, 
year = {2003}, 
rating = {0}, 
title = {{Commuted waveguide synthesis of the clavichord}}, 
author = {Laurson, M and Erkut, Cumhur}, 
journal = {Computer Music Journal}, 
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0242586053\&partnerID=40}, 
pages = {71 82}, 
number = {1}, 
volume = {27}, 
note = {Cited By (since 1996): 7 
Export Date: 11 November 2009

Source: Scopus}, 
keywords = {}
}
@inproceedings{Grani:2015ul, 
year = {2015}, 
rating = {0}, 
author = {Grani, Francesco and Overholt, Dan and Erkut, Cumhur and Gelineck, Steven and Triantafyllidis, Georgios and Nordahl, R and Serafin, Stefania}, 
title = {{Spatial Sound and Multimodal Interaction in Immersive Environments}}, 
isbn = {9781450338967}, 
doi = {10.1145/2814895.2814919}, 
abstract = {{Spatial sound and interactivity are key elements of investigation at the Sound And Music Computing master program at Aalborg University Copenhagen. We present a collection of research directions and recent results from work in these areas, with the focus ...}}, 
urldate = {0}, 
pages = {1 5}, 
series = {Audio Mostly}, 
keywords = {}
}
@techreport{eNTF07-report, 
year = {2007}, 
rating = {3}, 
keywords = {chi-08,cost-sid,needkeywords,schema-sid}, 
author = {Drayson, Hannah and Erkut, Cumhur and Filatriau, Jehan-Julien and Frisson, Christian and Gundogdu, Umut and Knapp, Ben and Lehembre, Rémy and Mühl, Christian and Perez, Miguel Angel Ortiz and Sayin, Alaattin and Soleymani, Mohammad and Tahiroğlu, Koray and Benovoy, Mitchel and Corcoran, Thomas Greg}, 
title = {{Audiovisual Content Generation Controlled by Physiological Signals for Clinical and Artistic Applications}}, 
url = {http://enterface.net}, 
abstract = {{NeedAbstract}}, 
note = {\#chi-08 \#cost-sid \#needkeywords \#schema-sid}, 
month = {08}
}
@inproceedings{Erkut06:NoMute, 
year = {2006}, 
rating = {0}, 
keywords = {schema}, 
author = {Erkut, Cumhur}, 
title = {{Towards physics-based control and sound synthesis of multi-agent systems: Application to synthetic hand clapping}}, 
url = {http://www.nomute.no}, 
urldate = {0}, 
series = {Proc. Nordic Music Tech. Conf.}, 
note = {\#schema}, 
month = {10}
}
@inproceedings{Erkut:2008, 
year = {2008}, 
rating = {1}, 
keywords = {CHI,chi-08}, 
author = {Erkut, Cumhur and Filatriau, Jehan-Julien and Lehembre, Rémy and Ekman, Inger}, 
title = {{Sonic Interaction Design with Physiological Interfaces in a Workshop Setting}}, 
urldate = {0}, 
pages = {6}, 
series = {Conf. Human Factors in Computing Systems}, 
note = {\#CHI \#chi-08 Florence, Italy}, 
month = {04}
}
@article{Widmer:2007ch, 
year = {2007}, 
rating = {0}, 
title = {{Sound and Music Computing: Research Trends and Some Key Issues}}, 
author = {Widmer, Gerhard and Rocchesso, Davide and Erkut, Cumhur and Gouyon, Fabien and Pressnitzer, Daniel and Penttinen, Henri and Polotti, Pietro and Volpe, Gualtiero}, 
journal = {Journal of New Music}, 
doi = {10.1080/09298210701859222}, 
url = {http://www.tandfonline.com/doi/abs/10.1080/09298210701859222}, 
abstract = {{Abstract This contribution attempts to give an overview of current research trends and open research problems in the rich field of Sound and Music Computing (SMC). To that end, the field is roughly divided into three large areas related to Sound, Music, and Interaction, respectively, and within each of these, major research trends are briefly described. In addition, for each sub-field a small number of open research (or research strategy) issues are identified that should be addressed in order to further advance the SMC field.}}, 
pages = {169 184}, 
number = {3}, 
volume = {36}, 
language = {English}, 
keywords = {}
}
@techreport{Erkut:2012wn, 
year = {2012}, 
rating = {0}, 
keywords = {product}, 
author = {Erkut, Cumhur}, 
title = {{Product Sound Design}}, 
pages = {4 years}, 
note = {\#product sound design}
}
@inproceedings{Jylha:2012wk, 
year = {2012}, 
rating = {0}, 
keywords = {bayesian,biometric,hand,hmm,schema-sid,sid,sonic}, 
author = {Jylhä, Antti and Erkut, Cumhur and Simsekli, Umut and Cemgil, Ali Taylan}, 
title = {{Sonic Handprints: Person Identification with Hand Clapping Sounds by a Model-Based Method}}, 
url = {http://www.aes.org/e-lib/browse.cfm?elib=16186}, 
urldate = {0}, 
pages = {27 32}, 
series = {AES 45th Conference }, 
note = {\#bayesian \#biometric \#hand claps \#hmm \#schema-sid \#sid \#sonic gesture}, 
month = {04}
}
@inproceedings{Erkut:2011ua, 
year = {2011}, 
rating = {0}, 
keywords = {Product,PRSD,psd,sound}, 
author = {Erkut, Cumhur}, 
title = {{Product Sound Design: Past, Present, Future}}, 
urldate = {0}, 
pages = {37 43}, 
series = {Akustiikkapäivät 2011}, 
note = {\#Product sounds \#PRSD \#psd \#sound quality}, 
month = {05}
}
@inproceedings{Jylha:2008tx, 
year = {2008}, 
rating = {0}, 
author = {Jylhä, Antti and Erkut, Cumhur}, 
title = {{Sonic interactions with hand clap sounds}}, 
urldate = {0}, 
pages = {93 100}, 
series = {Proc. Audio Mostly}, 
keywords = {}, 
month = {05}
}
@techreport{Overholt:2016ue, 
year = {2016}, 
rating = {0}, 
author = {Overholt, Dan and Erkut, Cumhur}, 
title = {{Drive of Musical HCI: Design and Evaluation Concerns For Real-Time Interactions}}, 
pages = {1 4}, 
keywords = {}, 
month = {01}
}
@article{Coutrix:2010wc, 
year = {2010}, 
rating = {0}, 
title = {{Sonic Interaction for Multitouch Displays: Design, Development, and Evaluation (SIMULS)}}, 
author = {Coutrix, Céline and Erkut, Cumhur and Jylhä, Antti}, 
pages = {1 5}, 
keywords = {}, 
month = {02}
}
@inproceedings{Fehr:2015vk, 
year = {2015}, 
rating = {0}, 
author = {Fehr, Jonas and Erkut, Cumhur}, 
title = {{LichtGestalt: Interaction with Sound Through Swarms of Light Rays}}, 
url = {https://easychair.org/conferences/submission\_upload\_z.cgi?a=8923559;uploaded=1;submission=2331516;track=117345}, 
urldate = {0}, 
pages = {1 6}, 
series = {Sound and Music Computing Conference}, 
keywords = {}, 
month = {06}
}
@inproceedings{Erkut:2009wu, 
year = {2009}, 
rating = {0}, 
author = {Erkut, Cumhur and Jylhä, Antti and Ekman, Inger}, 
title = {{Recent advances in exploring self-induced sonic interactions in the context of performing arts}}, 
urldate = {0}, 
pages = {1 2}, 
series = {Haptic and Audio Interaction Design, Intl. Workshop}, 
keywords = {}, 
month = {06}
}
@inproceedings{DelleMonache:2010gi, 
year = {2010}, 
rating = {0}, 
author = {Monache, Stefano Delle and Hug, Daniel and Erkut, Cumhur}, 
title = {{Basic Exploration of Narration and Performativity for Sounding Interactive Commodities}}, 
isbn = {978-3-642-15840-7}, 
doi = {10.1007/978-3-642-15841-4\_8}, 
abstract = {{We present an exploration in sonic interaction design, aimed at integrating the power of narrative sound design with the sonic aesthetics of a physics-based sound synthesis. The emerging process is based on interpretation, and can represent a novel tool in the ...  }}, 
urldate = {0}, 
pages = {65 74}, 
volume = {6306}, 
series = {Haptic and Audio Interaction Design, Intl. Workshop}, 
keywords = {}
}
@inproceedings{Serafin:2014wn, 
year = {2014}, 
rating = {0}, 
author = {Serafin, Stefania and Dahl, Sofia and Gotzen, Amalia De and Erkut, Cumhur and Overholt, Dan and Purwins, Hendrik and Sturm, B}, 
title = {{Sound and Music Computing at Aalborg University in Copenhagen}}, 
urldate = {0}, 
pages = {1 4}, 
series = {Intl. Computer Music Conf.}, 
keywords = {}, 
month = {09}
}
@incollection{Erkut:2013uk, 
year = {2013}, 
rating = {0}, 
keywords = {iPalmas,Product,PRSD,psd,rhythmicity}, 
title = {{Heigh Ho: Rhythmicity in sonic interaction}}, 
author = {Erkut, Cumhur and Jylhä, Antti and Rocchesso, Davide}, 
editor = {Serafin, Stefania and Franinovic, Karmen}, 
url = {http://xplqa30.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6504637\&contentType=Books+\%26+eBooks\&}, 
urldate = {0}, 
pages = {341 350}, 
series = {Sonic Interaction Design}, 
publisher = {MIT Press}, 
note = {\#iPalmas \#Product sounds \#PRSD \#psd \#rhythmicity}
}
@incollection{Erkut:2011wn, 
year = {2011}, 
rating = {0}, 
title = {{Product sound design}}, 
author = {Erkut, Cumhur and Monache, Stefano Delle and Rocchesso, Davide}, 
urldate = {0}, 
pages = {35 38}, 
series = {Explorations in Sonic Interaction Design}, 
publisher = {Logos Verlag}, 
keywords = {}
}
@inproceedings{Erkut:2011uf, 
year = {2011}, 
rating = {0}, 
author = {Erkut, Cumhur and Jylhä, Antti}, 
title = {{Rhytmic Blueprints}}, 
url = {http://dl.acm.org/citation.cfm?id=2181038}, 
urldate = {0}, 
pages = {1 2}, 
series = {MindTrek}, 
keywords = {}, 
month = {09}
}
@techreport{Erkut:2011ve, 
year = {2011}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{Aalto STG: Product Sound Design}}, 
pages = {4 years}, 
keywords = {}
}
@techreport{Erkut:qn3bvZwe, 
year = {2007}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{Synthesis, Control, and Hierarchical Event Modeling Algorithms for Sonic Interaction Design}}, 
pages = {12}, 
keywords = {}
}
@inproceedings{Erkut:2013ta, 
year = {2013}, 
rating = {0}, 
author = {Erkut, Cumhur and Jylhä, Antti and Serafin, Stefania}, 
title = {{(and Sound) of SiMPE: Showcasing Outcomes of a Mobile Audio Programming Seminar}}, 
urldate = {0}, 
series = {SiMPE '13 in MobileHCI '13}, 
keywords = {}, 
month = {07}
}
@inproceedings{Jylha:2009uc, 
year = {2009}, 
rating = {0}, 
author = {Jylhä, Antti and Erkut, Cumhur and Ekman, Inger and Tahiroğlu, Koray}, 
title = {{iPalmas - An interactive ﬂamenco rhythm machine}}, 
urldate = {0}, 
pages = {1 2}, 
series = {Proc. Audio Mostly}, 
keywords = {}, 
month = {05}
}
@techreport{Fontana:2014wj, 
year = {2014}, 
rating = {0}, 
author = {Fontana, Federico and Serafin, Stefania and Erkut, Cumhur}, 
title = {{Piano from Nothing}}, 
pages = {1 76}, 
keywords = {}
}
@inproceedings{Karjalainen:2004wu, 
year = {2004}, 
rating = {3}, 
author = {Karjalainen, Matti and Pakarinen, Jyri and Erkut, Cumhur and Esquef, Paulo A A and Välimäki, Vesa}, 
title = {{Recent Advances in Physical Modeling with K- and W-Techniques}}, 
urldate = {0}, 
pages = {1 6}, 
series = {Proc. Intl. Conf. Digital Audio Effects (DAFx)}, 
keywords = {}, 
month = {09}
}
@inproceedings{Jylha:2013vq, 
year = {2013}, 
rating = {0}, 
author = {Jylhä, Antti and Erkut, Cumhur and Jacucci, Giulio}, 
title = {{I Can Hear You: Private, Public, and Social Sonic Interactions in Public Spaces}}, 
urldate = {0}, 
series = {Experiencing Interactivity in Public Spaces }, 
keywords = {}, 
month = {04}
}
@inproceedings{Erkut01:ICMC, 
year = {2001}, 
rating = {0}, 
keywords = {physical,Sound}, 
author = {Erkut, Cumhur and Laurson, M and Kuuskankare, M}, 
title = {{Model-based synthesis of the ud and the Renaissance lute}}, 
url = {http://lib.hut.fi/Diss/2002/isbn9512261901/article7.pdf}, 
abstract = {{Abstract We describe techniques for sound synthesis of the ud and the Renaissance lute using the physical modeling approach. In the present model, novel methods have been used for the design of the loop filters, as well as for the implementation of the glissando ...}}, 
urldate = {2}, 
series = {Intl. Computer Music Conf.}, 
note = {\#physical modeling \#Sound Synthesis}
}
@inproceedings{Jylha:2012ue, 
year = {2012}, 
rating = {5}, 
keywords = {rhythmicity,sonic,walking}, 
author = {Jylhä, Antti and Erkut, Cumhur and Serafin, Stefania}, 
title = {{Rhythmic Walking Interactions with Auditory Feedback: an Exploratory Study}}, 
url = {http://dl.acm.org/citation.cfm?id=2371467\&dl=ACM\&coll=DL\&CFID=193168740\&CFTOKEN=28327967}, 
urldate = {0}, 
pages = {68 75}, 
series = {Audio Mostly}, 
note = {\#rhythmicity \#sonic interaction design \#walking}
}
@misc{ProductSoundDesign:2011wn, 
year = {2011}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{Product Sound Design}}, 
urldate = {0}, 
keywords = {}
}
@article{Erkut02:JASA, 
year = {2002}, 
rating = {0}, 
keywords = {baltic-psaltery,digital,musical,nonlinear,physical,ropp,schema,sound,tension-modulation,zither}, 
title = {{Acoustical analysis and model-based sound synthesis of the kantele}}, 
author = {Erkut, Cumhur and Karjalainen, Matti and Huang, P and Välimäki, Vesa}, 
journal = {J Acoust Soc Am}, 
issn = {0001-4966}, 
doi = {10.1121/1.1504858}, 
pmid = {12398473}, 
abstract = {{The five-string Finnish kantele is a traditional folk music instrument that has unique structural features, resulting in a sound of bright and reverberant timbre. This article presents an analysis of the sound generation principles in the kantele, based on measurements and ...}}, 
pages = {1681 1691}, 
number = {4}, 
volume = {114}, 
note = {\#baltic-psaltery \#digital waveguide \#musical acoustics \#nonlinear \#physical modeling \#ropp \#schema \#sound source modeling \#sound source modeling \#tension-modulation \#zither PMID: 12398473}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2002.pdf}
}
@article{Erkut:2007ue, 
year = {2007}, 
rating = {0}, 
title = {{ClaPD: A testbed for control of multiple sound sources in interactive and participatory contexts}}, 
author = {Erkut, Cumhur and Tahiroğlu, Koray}, 
url = {https://www.semanticscholar.org/paper/ClaPD\%3A-A-testbed-for-control-of-multiple-sound-in-Erkut-Tahiroglu/9f3da83f9d33e3e22eb6b7e348007514aebf5478\#extracted}, 
abstract = {{PureData Convention 2007, (Montreal, Canada), August 21-26 2007. Online proceedings at http://artengine.ca/\textbackslashtextasciitildecatalogue-pd.}}, 
keywords = {}
}
@inproceedings{Erkut01:SCI, 
year = {2001}, 
rating = {0}, 
keywords = {physical,Sound}, 
author = {Erkut, Cumhur}, 
title = {{Model order selection techniques for the loop filter design of virtual string instruments}}, 
urldate = {0}, 
pages = {529 534}, 
volume = {10}, 
note = {\#physical modeling \#Sound Synthesis}, 
month = {07}
}
@article{Valimaki:2004ik, 
year = {2004}, 
rating = {0}, 
title = {{Sound Synthesis of the Harpsichord Using a Computationally Efficient Physical Model}}, 
author = {Penttinen, Henri and Knif, J and Laurson, Mikael and Erkut, Cumhur}, 
journal = {EURASIP Journal on Advances in Signal Processing}, 
doi = {10.1155/s111086570440211x}, 
abstract = {{Abstract A sound synthesis algorithm for the harpsichord has been developed by applying the principles of digital waveguide modeling. A modification to the loss filter of the string model is introduced that allows more flexible control of decay rates of partials than is ...}}, 
pages = {934 948}, 
number = {7}, 
volume = {2004}, 
language = {English}, 
note = {Here is the first version plan, on June 2, 2003 
1. Intro
+ basics of physical modeling, digital waveguide synthesis, and commuted synthesis
+ brief overview of the harpsichord (could be separate section, if enough signal processing, like signal analysis, spectra etc)
2. Synthesis algorithm
- Structure of string model: Jaffe - Smith structure including a one-pole filter with ripples, all pass FD filter, in harmonizing all pass filters (?), parallel resonator(s) for beating
- Overall model structure: excitation sample database, string model, quill samples, soundboard filter
3. Calibration of the synthesis algorithm
- Recording techniques (brief)
- Analysis of harpsichord tones: STFT and decay time analysis (brief)
- Simplified loop filter design: g, a, and r parameters
- Design of soundboard model
4. Implementation and applications
- New PWSynth, ENP 2.0
- Comments of musical potential and applications (musicians, composers, lutherists)
5. Conclusions
- New contributions: new instrument, extended loop filter, better and easier calibration, soundboard filter
6. References
- Main papers and book chapters on harpsichord acoustics
- Commuted synthesis papers 
- Calibration techniques (Välimäki, Tolonen, Erkut, Bank)
- Similar sound synthesis papers (Karjalainen'98, CMJ'03 clavichord)
- Basic references to ENP and PWSynth}, 
keywords = {}
}
@article{Erkut:2002tha, 
year = {2002}, 
rating = {0}, 
title = {{Aspects in analysis and model-based sound synthesis of plucked string instruments}}, 
author = {Erkut, Cumhur}, 
url = {http://lib.tkk.fi/Diss/2002/isbn9512261901/isbn9512261901.pdf}, 
abstract = {{Abstract This thesis consists of an introduction and nine articles. The general framework of the articles is the analysis and synthesis of plucked string instruments. The articles document acoustical analysis and model-based sound synthesis of the tanbur, the kantele ...}}, 
keywords = {}
}
@inproceedings{Erkut:2008tb, 
year = {2008}, 
rating = {0}, 
author = {Erkut, Cumhur and Jylhä, Antti and Altinsoy, Ercan M}, 
title = {{Audio-tactile interaction at the nodes of a block-based physical sound synthesis model}}, 
url = {http://www.ias.et.tu-dresden.de/ias/fileadmin/user\_upload/akustik/Forschung/altinsoy\_alt/28\_1\_.pdf}, 
urldate = {0}, 
series = {Haptic and Audio Interaction Design, Intl. Workshop}, 
keywords = {}
}
@inproceedings{Anonymous:2009tx, 
year = {2009}, 
rating = {0}, 
author = {Pulkki, Ville and Laitinen, Mikko-Ville and Erkut, Cumhur}, 
title = {{Efﬁcient spatial sound synthesis for virtual worlds}}, 
urldate = {0}, 
pages = {10}, 
series = {AES Intl. Conf.}, 
keywords = {}
}
@book{Karjalainen:2004ue, 
year = {2004}, 
rating = {0}, 
title = {{Digital Waveguides vs. Wave Digital Filters in physical modeling: Theoretical and computational aspects}}, 
author = {Karjalainen, Matti and Erkut, Cumhur}, 
isbn = {978-320-0001-65-7}, 
abstract = {{Digital Waveguides (DWG) are known as a highly efficient approach to physical modeling and sound synthesis of musical instruments. Recently there has been increasing interest in studying other discrete-time paradigms such as Finite Difference Time Do...}}, 
urldate = {0}, 
series = {Signal Processing Conference}, 
publisher = {IEEE}, 
language = {English}, 
keywords = {}
}
@inproceedings{Erkut:2005vq, 
year = {2005}, 
rating = {0}, 
author = {Erkut, Cumhur}, 
title = {{Modular interactions and hybrid models: a conceptual map for model-based sound synthesis}}, 
url = {http://www.acoustics.hut.fi/\textbackslashtextasciitildecerkut/pubs/preprint/2005/Erkut05\_Eusipco.pdf}, 
abstract = {{ABSTRACT This paper presents a conceptual map for model-based sound synthesis (MBSS). This map emphasizes the role of modular interaction between sub-models and it provides a natural framework for hybrid models. The MBSS techniques are grouped ...}}, 
urldate = {0}, 
pages = {1 4}, 
keywords = {}
}
@article{Laurson:2001tx, 
year = {2001}, 
rating = {0}, 
title = {{Methods for Modeling Realistic Playing in Acoustic Guitar Synthesis}}, 
author = {Laurson, Mikael and Erkut, Cumhur and Välimäki, Vesa and Kuuskankare, Mika}, 
journal = {Computer Music Journal}, 
doi = {10.1162/014892601753189529}, 
pages = {38 49}, 
number = {3}, 
volume = {25}, 
language = {English}, 
note = {Cited By (since 1996): 15 
Export Date: 11 November 2009

Source: Scopus}, 
keywords = {}, 
month = {09}
}
@techreport{Serafin:2013vs, 
year = {2013}, 
rating = {0}, 
author = {Serafin, Stefania and Erkut, Cumhur}, 
title = {{Spatialized audio haptic feedback for training and rehabilitation}}, 
pages = {1 13}, 
keywords = {}
}
@book{Erkut:2014hm, 
year = {2014}, 
rating = {0}, 
title = {{Design and evaluation of interactive musical fruit}}, 
author = {Erkut, Cumhur and Serafin, Stefania and Fehr, Jonas and Figueira, Henrique M.R. Fernandes and Hansen, Theis B. and Kirwan, Nicholas J. and Zakarian, Mariam R.}, 
isbn = {9781450322720}, 
url = {http://dl.acm.org/citation.cfm?id=2593968.2610451\&coll=DL\&dl=GUIDE\&CFID=457777488\&CFTOKEN=50784383}, 
abstract = {{In this paper we describe the design and evaluation of a novel, tangible user interface for interaction with sound, to be implemented in a museum setting. Our workinprogress is part of a larger concept for an installation prioritizing a collaborative, explorative, multimodal experience. Focus has been centered on novice children, in order to accommodate all potential users of the museum, and to minimize the risk of excluding users based on skill or previous musical knowhow. We have developed four instances of a multimodal device for interacting with sounds via a tangible interface, and called them Interactive Musical Fruits (IMFs). The IMF consists of an embedded processing system, which can detect its orientation. Qualitative testing with children has been performed, to better evaluate the current design state. Positive feedback from the test subjects upholds the validity and the potential of the IMF as an interface in a museum context. However, further research is required to improve the interactive and collaborative aspects of the device, as well as the aural and visual properties of the IMF.}}, 
urldate = {0}, 
series = {IDC '14}, 
publisher = {ACM}, 
keywords = {}, 
doi = {10.1145/2593968.2610451}, 
month = {06}
}
@article{Pirhonen:2017ix, 
year = {2017}, 
rating = {0}, 
title = {{Human-Technology Choregraphies: Body, Movement, and Space in Expressive Interactions}}, 
author = {Pirhonen, Antti and Tuuri, Kai and Erkut, Cumhur}, 
journal = {Human Technology}, 
doi = {10.17011/ht/urn.201705272515}, 
pages = {6 9}, 
number = {1}, 
volume = {13}, 
keywords = {}, 
month = {05}
}
@article{serafin-2018-sonic-inter, 
year = {2018}, 
rating = {0}, 
title = {{Sonic Interactions in Virtual Reality}}, 
author = {Serafin, Stefania and Geronazzo, Michele and Erkut, Cumhur and Nilsson, Niels C. and Nordahl, Rolf}, 
journal = {IEEE Computer Graphics and Applications}, 
issn = {0272-1716}, 
doi = {10.1109/mcg.2018.193142628}, 
pmid = {29672254}, 
url = {https://www.overleaf.com/11328897cnyxybjnxqqw}, 
abstract = {{A high-fidelity but efficient sound simulation is an essential element of any VR experience. Many techniques used in virtual acoustics are graphical rendering techniques suitably modified to account for sound generation and propagation. In recent years, several advances in hardware and software technologies have been facilitating the development of immersive interactive sound-rendering experiences. In this article, we present a review of the state of the art of such simulations, with a focus on the different elements that, combined, provide a complete interactive sonic experience. This includes physics-based simulation of soundeffects and their propagation in space together with binaural rendering to simulate the position of sound sources. We present how these different elements of the sound design pipeline have been addressed in the literature, trying to find the trade-off between accuracy and plausibility. Recent applications and current challenges are also presented.}}, 
pages = {31--43}, 
number = {2}, 
volume = {38}, 
keywords = {}
}
@book{Serafin:2016vf, 
year = {2016}, 
rating = {0}, 
title = {{Virtual reality and the senses}}, 
author = {Serafin, Stefania and Nilsson, Niels Christian and Erkut, Cumhur and Nordahl, R}, 
isbn = {978-87-643-1317-8}, 
url = {https://issuu.com/danishsound/docs/dtu\_whitepaper\_2017\_singlepages}, 
urldate = {0}, 
series = {Danish Sound Innovation Network}, 
publisher = {Danish Sound Innovation Network}, 
keywords = {}, 
month = {11}
}
@article{Erkut:2014tr, 
year = {2015}, 
rating = {0}, 
keywords = {Dance,embodied}, 
title = {{Arts and Technology}}, 
author = {Erkut, Cumhur and Rajala-Erkut, Anu and Dahl, Sofia}, 
journal = {Arts and Technology}, 
issn = {1867-8211}, 
doi = {10.1007/978-3-319-18836-2\_10}, 
abstract = {{We present approaches for teaching and designing embodied interaction in collaboration with a contemporary dance choreographer. Our approaches are based on the felt qualities of movement, providing a shared experience, vocabulary for self-expression, and appreciation for movement as a design material for interaction design practitioners. In parallel, such activities provide art professionals competencies for new contexts. We present two workshops conducted at different times. The first workshop, back in 2009, brought about novel sonic interaction paradigms, technologies, and artifacts. The second workshop was carried out in March 2014, and we are in the process of developing interactive sketches by pairing our observations with motion tracking. In this paper, the activities in these workshops are presented, and reflected upon. In particular, we are investigating whether or not these activities guided the participants from the prevailing notion of command/control in embodied interaction towards experiences related to the felt qualities of movement.}}, 
pages = {77--85}, 
number = {Chapter 10}, 
volume = {145}, 
note = {\#Dance \#embodied interaction}
}
@inproceedings{Serafin:2015ej, 
year = {2015}, 
rating = {0}, 
author = {Serafin, Stefania and Gotzen, Amalia De and Dimitrov, Smilen and Gelineck, Steven and Erkut, Cumhur and Nilsson, Niels Christian and Grani, Francesco and Nordahl, R and Trento, Stefano}, 
title = {{The digital Intonarumori}}, 
isbn = {978-1-4673-6886-5}, 
doi = {10.1109/3dui.2015.7131773}, 
url = {message:\%3CD0BEEB87.23484\%25sts@create.aau.dk\%3E}, 
abstract = {{The Intonarumori (Noise Intoners) were a family of musical instruments designed and built by the Italian composer and painter Luigi Russolo at the beginning of the 20th century (see Figure 1). Each Intonarumori was made of a colorful parallelepipedal sound box with a  }}, 
urldate = {0}, 
pages = {207 208}, 
series = {2015 IEEE Symposium on 3D User Interfaces (3DUI)}, 
note = {Points of departure: 
- Continous control
- Leap Motion Virtualization
- Commuted synth}, 
keywords = {}
}
@article{Mandanici:2018ts, 
year = {2018}, 
rating = {0}, 
title = {{Movement Patterns in the Harmonic Walk Interactive Environment}}, 
author = {Mandanici, Marcella and Erkut, Cumhur and Paisa, Razvan and Serafin, Stefania}, 
journal = {Journal of New Music Research}, 
url = {https://www.overleaf.com/}, 
abstract = {{The online platform for scientific writing. Overleaf is free: start writing now with one click. No sign-up required. Great on your iPad.}}, 
pages = {1 17}, 
keywords = {}, 
month = {05}
}
@article{Maculewicz:2015uk, 
year = {2015}, 
rating = {0}, 
title = {{Rhythmic Walking Interaction with Auditory Feedback: Ecological Approaches in a Tempo Following Experiment}}, 
author = {Maculewicz, Justyna and Jylha, Antti and Serafin, Stefania and Erkut, Cumhur}, 
journal = {IEEE MultiMedia}, 
issn = {1070-986X}, 
doi = {10.1109/mmul.2015.27}, 
abstract = {{This study presents a system capable of rhythmic walking interactions by auditory display. The feedback is based on footstep sounds, and follows either detected footsteps, or suggests a tempo, which is either constant or adapts to the walker. The auditory display contains simple sinusoidal tones or ecological, physically-based synthetic walking sounds. In the tempo-following experiment, we investigate the different interaction modes (step versus constant or adaptive tempo) and auditory feedback (sinusoidal tones versus ecological walking sounds) with respect to their effect on the walking tempo. Quantitatively, we calculate the mean square error (MSE) between the performed and target tempo, and the stability of the performed tempo. The results indicate that the MSE with ecological sounds is better or comparable to that with the sinusoidal tones, yet ecological sounds are considered more natural. Allowing deviations from the cues in the adaptive conditions results in a tempo that is still stable, but closer to the natural walking pace of the subjects. These results have implications on the design of interactive entertainment or rehabilitation.}}, 
pages = {1--1}, 
number = {99}, 
volume = {PP}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Maculewicz-2015.pdf}
}


@inproceedings{Fehr:2015ke, 
year = {2015}, 
rating = {0}, 
author = {Fehr, Jonas and Erkut, Cumhur}, 
title = {{Indirection between movement and sound in an interactive sound installation}}, 
isbn = {9781450334570}, 
doi = {10.1145/2790994.2791016}, 
url = {http://dl.acm.org/citation.cfm?id=2791016\&CFID=537732660\&CFTOKEN=36827438}, 
abstract = {{We present a new interactive sound installation to be explored by movement, specifically by the movement qualities extracted from the motion tracking data. There is an indirection between movement and sound: movement qualities control a dynamical system (in our case a flock of agents), which in turn controls the visual and sonic feedback of the interface. The movement qualities are extracted by simple measures. The system is implemented, evaluated, and will be demonstrated during MOCO'15.}}, 
urldate = {0}, 
pages = {160--163}, 
series = {the 2nd International Workshop}, 
keywords = {}, 
month = {08}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Fehr-2015.pdf}
}
@inproceedings{Jylha:2008kc, 
year = {2008}, 
rating = {0}, 
author = {Jylhä, Antti and Erkut, Cumhur}, 
title = {{Interring the Hand Configuration from Hand Clapping Sounds}}, 
doi = {10.1111/2041-210x.12224/full}, 
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.218.9002\&rep=rep1\&type=pdf}, 
abstract = {{ABSTRACT In this paper, a technique for inferring the configuration of a clapper's hands from a hand clapping sound is described. The method was developed based on analysis of synthetic and recorded hand clap sounds, labeled with the corresponding hand  }}, 
urldate = {0}, 
series = {Proc. Intl. Conf. Digital Audio Effects (DAFx)}, 
keywords = {}
}
@techreport{Erkut:2016wi, 
year = {2016}, 
rating = {0}, 
author = {Erkut, Cumhur and Dahl, Sofia}, 
title = {{Movement and Coding in an Embodied Interaction Course}}, 
url = {http://mobilelifecentre.org/node/1671}, 
abstract = {{Movement-based design is reaching critical mass in HCI, and we can start to identify strategies, similarities and differences in how it is approached. Similarities may include, for example, a strong first person perspective on design, emphasising movement, somatics and aesthetic sensibilities of the designer, as well as starting from the premise that our bodily ways of being in the world are shaped by the ecologies of people, cultural practices and the artefacts we create and use. The workshop will discuss similarities and differences between specific design exemplars; ways of extending on our senses and perception – even creating new senses through technology; social interactions, engaging us to jointly explore movement or touch; endowing machines with their own ‘somatics’; as well as engaging in larger political issues around the body, such as gender perspectives, or challenging the mind-body divide.}}, 
pages = {1 3}, 
keywords = {}, 
month = {01}
}
@article{Anonymous:2005um, 
year = {2005}, 
rating = {0}, 
title = {{Design and analysis of a modified kantele with increased loudness}}, 
author = {Penttinen, Henri and Erkut, Cumhur and Pölkki, J}, 
journal = {Acta Acustica united with Acustica}, 
abstract = {{The kantele, an ancient plucked string instrument, belongs to the family of zithers, and it is still used in traditional folk music in Finland, Northwest Russia, and the Baltic countries. Design rules for making the kantele louder are proposed and confirming analysis results are presented. A description of the main characteristics of the traditional design of the kantele is given, so that it supports the presentation of the design rules and analysis results. The ... }}, 
keywords = {}
}
@article{Erkut:2013uh, 
year = {2013}, 
rating = {0}, 
title = {{Mobile Probes for Special Needs}}, 
author = {Erkut, Cumhur}, 
abstract = {{ABSTRACT At our institute we currently run several projects in a Technology-enhanced Learning Environment (TEL) with and for the children with special needs. Families participate as experts in the development and evaluation process by sharing feedback ... }}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2013_2.pdf}
}
@inproceedings{Hagensen:2016tk, 
year = {2016}, 
rating = {0}, 
author = {Hagensen, Troels Lunde and Serafin, Stefania and Erkut, Cumhur}, 
title = {{An Experimental Study in Generative Music for Exercising to Ease Perceived Exertion by use of Heart Beat Rate as a Control Parameter}}, 
urldate = {0}, 
pages = {1 4}, 
series = {Student Interaction Design Research conference}, 
keywords = {}, 
month = {03}
}
@inproceedings{Erkut:2011wz, 
year = {2011}, 
rating = {0}, 
keywords = {iPalmas,NIME,rhythmicity}, 
author = {Erkut, Cumhur and Jylhä, Antti and Discioglu, Reha}, 
title = {{A Structured Design and Evaluation Model with Application to Rhythmic Interaction Displays}}, 
doi = {10.5281/zenodo.1178003}, 
url = {http://www.nime.org/proceedings/2011/nime2011\_477.pdf}, 
urldate = {0}, 
pages = {477–480}, 
series = {New Interfaces for Musical Expression}, 
note = {\#iPalmas \#nime \#rhythmicity}
}
@inproceedings{Serafin.2016.AM '16, 
year = {2016}, 
rating = {0}, 
author = {Serafin, Stefania and Erkut, Cumhur and Kojs, Juraj and Nordahl, Rolf and Nilsson, Niels C.}, 
title = {{Virtual reality musical instruments: Guidelines for multisensory interaction design}}, 
isbn = {9781450348225}, 
doi = {10.1145/2986416.2986431}, 
abstract = {{The rapid development and availability of low cost technologies has created a wide interest in virtual reality (VR), but how to design and evaluate multisensory interactions in VR remains as a challenge. In this paper, we focus on virtual reality musical instruments, present an overview of our design and evaluation guidelines, and examine historical case studies. Our main contribution is to inform the design and evaluation of the future VRMIs and consider the challenges.}}, 
urldate = {0}, 
pages = {266--271}, 
series = {AM '16}, 
keywords = {}
}
@article{Maculewicz:2015gn, 
year = {2016}, 
rating = {0}, 
title = {{An investigation on the impact of auditory and haptic feedback on rhythmic walking interactions}}, 
author = {Maculewicz, Justyna and Erkut, Cumhur and Serafin, Stefania}, 
journal = {International Journal of Human-Computer Studies}, 
issn = {1071-5819}, 
doi = {10.1016/j.ijhcs.2015.07.003}, 
url = {http://www.sciencedirect.com/science/article/pii/S1071581915001202}, 
abstract = {{This paper presents a system capable of rhythmic walking interaction by auditory and haptic display. Likewise, it summarizes the results of the research on the influence of the audio and haptic stimulation on rhythmic walking interaction. The system detects user’s footsteps and either provides interactive real-time feedback or suggests a pace using a synthetic walking sound or vibration. This pace is either a constant tempo or adapts to the walker. Auditory and haptic feedback signals are either ecological physically-based synthetic walking signals or simple sinusoidal beeps. In the experiment, the different auditory and haptic feedback and interaction modes are studied with respect to their effect on the walking tempo. The results show that participants synchronise equally well with the tempo with either audio or haptic cues, but indicate the audio–haptic conditions as the easiest to synchronise with. Moreover, results indicate that multimodal audio–haptic feedback provide the most natural feeling. These results have implications on the design of interactive entertainment or therapeutical applications.}}, 
pages = {40--46}, 
volume = {85}, 
language = {English}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Maculewicz-2016.pdf}
}
@incollection{Stovring:2016ir, 
year = {2017}, 
rating = {0}, 
title = {{Multi-kinect Skeleton Fusi on for Enactive Games}}, 
author = {Støvring, Nikolaj Marimo and Kaspersen, Esbern Torgard and Korsholm, Jeppe Milling and Najim, Yousif Ali Hassan and Makhlouf, Soraya and Khani, Alireza and Erkut, Cumhur}, 
isbn = {9783319558332}, 
url = {https://link.springer.com/chapter/10.1007/978-3-319-55834-9\_20}, 
abstract = {{We present a procedural method and an implementation of multi-Kinect skeleton fusion on Unity environment. Our method calibrates two Kinects by combining the relative coordinates of a user’s torso onto a single coordinate system. The method is tested with a small number of participants in scenarios involving multiple users, results indicate that the method provides an improvement over a single camera, and it is accurate enough for games and entertainment applications. The video demonstration of the system is provided, and future directions to improve accuracy are outlined.}}, 
urldate = {0}, 
pages = {173--180}, 
volume = {196}, 
series = {Interactivity, Game Creation, Design, Learning, and Innovation}, 
language = {English}, 
keywords = {}, 
doi = {10.1007/978-3-319-55834-9\_20}, 
month = {05}
}
@article{Serafin:2015fh, 
year = {2015}, 
rating = {0}, 
title = {{Sonic interaction in virtual environments}}, 
author = {Serafin, Stefania and Nordahl, R and Erkut, Cumhur}, 
journal = {2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments (SIVE)}, 
doi = {10.1109/sive.2015.7361283}, 
abstract = {{This paper summarizes the main research topics addressed at the 2<sup>nd</sup> workshop on Sonic Interaction in Virtual Environments (SIVE) that took place in Arles, France in March 2015. The workshop is part of the annual IEEE Virtual Reality Confer...}}, 
pages = {1 2}, 
language = {English}, 
keywords = {}
}
@article{Pirhonen:2016fe, 
year = {2016}, 
rating = {0}, 
title = {{Human-Technology Choreographies: Body, Movement, and Space}}, 
author = {Pirhonen, Antti and Tuuri, Kai and Erkut, Cumhur}, 
journal = {Human Technology}, 
doi = {10.17011/ht/urn.201605192617}, 
url = {http://humantechnology.jyu.fi/archives/abstracts/pirhonen\_tuuri\_erkut\_GEintroduction16.html}, 
pages = {1--4}, 
number = {1}, 
volume = {12}, 
keywords = {}
}
@inproceedings{Erkut:2015dc, 
year = {2015}, 
rating = {0}, 
author = {Erkut, Cumhur and Serafin, Stefania and Hoby, Michael and Sårde, Jonniy}, 
title = {{Product Sound Design: Form, Function, and Experience}}, 
isbn = {9781450338967}, 
doi = {10.1145/2814895.2814920}, 
abstract = {{Current interactive products, services, and environments are appraised by their sensory attributes, in addition to their form and function. Sound is an important factor in these multisensory product appraisals. Integrating this sound opportunity into the design and development of interactive products, which are fit for real-world, yet constitute a strong brand identity, remains a challenge. We address this challenge by applying the research know-how of an academic institution and business practices of a sound agency SME within the core R\&D and production process of the third industrial partner. Our approach has clear application scenarios in, e.g., extended wireless headsets, car audio appliances, and portable entertainment devices. We describe the prototypes developed during the project life span, and the activities and outcomes of a half-day workshop designed to disseminate the project results.}}, 
urldate = {0}, 
pages = {10}, 
series = {Audio Mostly}, 
keywords = {}
}


@inproceedings{Erkut:2017cc, 
year = {2017}, 
rating = {0}, 
author = {Erkut, Cumhur and Dahl, Sofia}, 
title = {{Embodied Interaction through Movement in a Course Work}}, 
isbn = {978-1-4503-5209-3}, 
doi = {10.1145/3077981.3078026}, 
urldate = {0}, 
pages = {1--8}, 
series = {Proceedings of the 4th International Conference on Movement Computing  - MOCO '17}, 
keywords = {}, 
month = {06}
}
@inproceedings{Maculewicz:2015vh, 
year = {2015}, 
rating = {0}, 
author = {Maculewicz, Justyna and Erkut, Cumhur and Serafin, Stefania}, 
title = {{An investigation on the influence of soundscapes and footstep sounds in affecting preferred walking pace}}, 
abstract = {{In this paper we describe an experiment whose goal is to investigate the role of footstep sounds and soundscapes to affect the pace of a person who is walking in place, eg, mimicking the act of walking without leaving the current position. The results of a ... }}, 
urldate = {0}, 
pages = {133 137}, 
series = {Intl. Conf. Auditory Displays}, 
keywords = {}
}
@book{Jylha:2010hj, 
year = {2010}, 
rating = {0}, 
title = {{Simulation of rhythmic learning: a case study}}, 
author = {Jylhä, Antti and Erkut, Cumhur and Pesonen, Matti and Ekman, Inger}, 
isbn = {9781450300469}, 
abstract = {{Simulation of human interaction with computational systems can inform their design and provide means for designing new, intelligent systems capturing some of the essence of human behavior. We describe a system simulating a situation, where a virtual tutor is teaching rhythms to a human learner. In this simulation, we virtualize the human behavior related to the learning of new rhythms. We inform the design of the system based on an experiment, in which a virtual tutor taught Flamenco hand clapping patterns to human subjects. Based on the findings on interaction with the system and learning of the patterns, we are simulating this learning situation with a virtual learning clapper. We also discuss the future work to be undertaken for more realistic, agent-based simulation of rhythmic interaction.}}, 
urldate = {0}, 
series = {the 5th Audio Mostly Conference}, 
publisher = {ACM}, 
keywords = {}, 
doi = {10.1145/1859799.1859819}, 
month = {09}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Jylhä-2010.pdf}
}
@article{Simsekli:2011ks, 
year = {2010}, 
rating = {0}, 
title = {{Real-Time Recognition of Percussive Sounds by a Model-Based Method}}, 
author = {Şimşekli, Umut and Jylhä, Antti and Erkut, Cumhur and Cemgil, A T}, 
journal = {EURASIP Journal on Advances in Signal Processing}, 
issn = {1687-6180}, 
doi = {10.1155/2011/291860}, 
abstract = {{Interactive musical systems require real-time, low-latency, accurate, and reliable event detection and classification algorithms. In this paper, we introduce a model-based algorithm for detection of percussive events and test the algorithm on the detection and classification of different percussive sounds. We focus on tuning the algorithm for a good compromise between temporal precision, classification accuracy and low latency. The model is trained offline on different percussive sounds using the expectation maximization approach for learning spectral templates for each sound and is able to run online to detect and classify sounds from audio stream input by a Hidden Markov Model. Our results indicate that the approach is promising and applicable in design and development of interactive musical systems.}}, 
pages = {291860}, 
number = {1}, 
volume = {2011}, 
language = {English}, 
note = {Recheck for bird onsets}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Şimşekli-2010.pdf}
}
@article{Maculewicz:2016us, 
year = {2016}, 
rating = {0}, 
title = {{How can soundscapes affect the preferred walking pace?}}, 
author = {Maculewicz, Justyna and Erkut, Cumhur and Serafin, Stefania}, 
journal = {Applied Acoustics}, 
doi = {10.1016/j.apacoust.2016.07.031}, 
pages = {230 239}, 
volume = {114}, 
language = {English}, 
keywords = {}
}
@article{Erkut:2017vg, 
year = {2017}, 
rating = {0}, 
title = {{Microphone-based Electronic Wind Instrument Using Feature Extraction}}, 
author = {Erkut, Cumhur}, 
pages = {1 10}, 
keywords = {}, 
month = {12}
}

@inproceedings{Erkut00:AES, 
year = {2000}, 
rating = {0}, 
keywords = {schema}, 
author = {Erkut, Cumhur and Välimäki, Vesa and Karjalainen, Matti and Laurson, Mikael}, 
title = {{Extraction of physical and expressive parameters for model-based sound synthesis of the classical guitar}}, 
urldate = {0}, 
pages = {17}, 
series = {Proc. AES Convention}, 
note = {\#schema}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2000.pdf}
}
@inproceedings{Kostiainen:2011tz, 
year = {2011}, 
rating = {0}, 
author = {Kostiainen, Juho and Erkut, Cumhur and Piella, Ferran Boix}, 
title = {{Design of an audio-based mobile journey planner application}}, 
isbn = {9781450308168}, 
doi = {10.1145/2181037.2181056}, 
url = {http://dl.acm.org/citation.cfm?id=2181056}, 
abstract = {{Using public transportation is a context in which awareness of time is important. Providing information related to both time and place by means of ambient media can not only remove the need to keep looking at the time in order to depart on time but also create the feel of being in control, by knowing the time available and the progress of the journey. In the mobile context, hands and eyes are often occupied, which significantly limits the amount of information that can be provided by typical applications based on textual and graphical interfaces. In this paper, we introduce a mobile journey planner application that utilizes audio in providing useful information as well as the user experience prototyping and design process behind it.}}, 
urldate = {0}, 
pages = {107--113}, 
series = {International Academic MindTrek Conference}, 
keywords = {}, 
month = {09}
}
@article{Laitinen:2012wb, 
year = {2012}, 
rating = {0}, 
keywords = {DirAC,psychoacoustics,spatial}, 
title = {{Parametric time-frequency representation of spatial sound in virtual worlds}}, 
author = {Laitinen, Mikko-Ville and Pihlajamäki, Tapani and Erkut, Cumhur and Pulkki, Ville}, 
journal = {ACM Transactions on Applied Perception (TAP)}, 
issn = {1544-3558}, 
doi = {10.1145/2207216.2207219}, 
url = {http://doi.acm.org/10.1145/2207216.2207219}, 
abstract = {{Directional audio coding (DirAC) is a parametric time-frequency domain method for processing spatial audio based on psychophysical assumptions and on energetic analysis of the sound field. Methods to use DirAC in spatial sound synthesis for virtual worlds are presented in this article. Formal listening tests are used to show that DirAC can be used to position and to control the spatial extent of virtual sound sources with good audio quality. It is also shown that DirAC can be used to generate reverberation for N-channel horizontal listening with only two monophonic reverberators without a prominent loss in quality when compared with quality obtained with N-channel reverberators.}}, 
pages = {8}, 
number = {2}, 
volume = {9}, 
language = {English}, 
note = {\#DirAC \#psychoacoustics \#spatial}, 
month = {06}
}
@book{Anonymous:2016wg, 
year = {2016}, 
rating = {0}, 
title = {{Electronic Armonica: a Tangible Musical Interface inspired by the Glass Harmonica}}, 
author = {Paisa, Razvan and Erkut, Cumhur and Serafin, Stefania}, 
isbn = {9781450348225}, 
abstract = {{This paper describes the design, implementation and evaluation of a tangible musical interface inspired by the glass harmonica, and two methods for synthesizing a glass sound: additive synthesis and physical modeling using banded waveguides. These methods were implemented in Pure Data and in Max/MSP, respectively. An interface was created using laser cutting and 3D printing tools. An Arduino microcontroller is used to create a virtual capacitive sensor for detecting touch. The interface has been evaluated in order to test its playability and to evaluate the overall behavior of the system. Besides having technical limitations expected from a prototype, the results are promising.}}, 
urldate = {0}, 
series = {the Audio Mostly 2016}, 
publisher = {ACM}, 
keywords = {}, 
doi = {10.1145/2986416.2986434}, 
month = {10}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Paisa-2016.pdf}
}
@inproceedings{Kirwan:2015tx, 
year = {2015}, 
rating = {0}, 
author = {Kirwan, Nicholas J and Overholt, Dan and Erkut, Cumhur}, 
title = {{Bean: A Digital Musical Instrument for Use in Music Therapy}}, 
doi = {10.5281/zenodo.851069}, 
abstract = {{(Abstract to follow)}}, 
urldate = {0}, 
keywords = {}, 
month = {07}
}
@inproceedings{Erkut:2016ic, 
year = {2016}, 
rating = {0}, 
author = {Erkut, Cumhur and Serafin, Stefania}, 
title = {{From Ecological Sounding Artifacts Towards Sonic Artifact Ecologies}}, 
isbn = {9781450340823}, 
doi = {10.1145/2851581.2892583}, 
url = {http://dl.acm.org/citation.cfm?doid=2851581.2892583}, 
abstract = {{The discipline of sonic interaction design has been focused on the interaction between a single user and an artifact. This strongly limits one of the fundamental aspects of music as a social and interactive experience. In this paper we propose sonic artifact ecologies as a mean to examine interactions between one or many users with one or many artifacts. Case studies from a recently run workshop on product sound design are examined.}}, 
urldate = {0}, 
pages = {560--570}, 
series = {the 2016 CHI Conference Extended Abstracts}, 
note = {Not moving.}, 
keywords = {}, 
month = {05}
}
@inproceedings{Erkut:2016ed, 
year = {2016}, 
rating = {0}, 
author = {Erkut, Cumhur and Rocchesso, Davide and Monache, Stefano Delle and Serafin, Stefania}, 
title = {{A Case of Cooperative Sound Design}}, 
isbn = {9781450347631}, 
doi = {10.1145/2971485.2996472}, 
url = {http://dl.acm.org/citation.cfm?doid=2971485.2996472}, 
abstract = {{In this design case study, protocol and linkographic analysis are applied to a task of cooperative vocal sketching, proposed in the scope of educational research activities. The understanding of the cognitive behaviors involved in sound creation is aimed at setting the ground for the development of rigorous, designerly evaluation practices tailored to sound design, all the way to the final interactive product. Relevant qualitative and quantitative information about the creative process informs the assessment and possibly improvement of sound design methods.}}, 
urldate = {0}, 
pages = {83}, 
series = {the 9th Nordic Conference}, 
keywords = {}
}
@book{Jylha:2011wx, 
year = {2011}, 
rating = {0}, 
keywords = {hand,rhythmicity,schema-sid,sonification}, 
title = {{Auditory feedback in an interactive rhythmic tutoring system}}, 
author = {Jylhä, Antti and Erkut, Cumhur}, 
isbn = {9781450310819}, 
url = {http://dl.acm.org/citation.cfm?doid=2095667.2095683}, 
abstract = {{We present the recent developments in the design of audio-visual feedback in iPalmas, the interactive Flamenco rhythm tutor. Based on evaluation of the original implementation, we have re-designed the interface to better support the user in learning and performing rhythmic patterns. The system measures the performance parameters of the user and provides auditory feedback on the performance with different sounds corresponding to different performance attributes. The design of these sounds is informed by several attributes derived from the evaluation. We propose informative, non-intrusive. and archetypal sounds to be used in the system.}}, 
urldate = {0}, 
series = {the 6th Audio Mostly Conference}, 
publisher = {ACM}, 
note = {\#hand claps \#rhythmicity \#schema-sid \#sonification Current version inserts copyright to captions and removes unnecessary inspiration figures. 
Current version inserts copyright to captions and removes unnecessary inspiration figures.}, 
doi = {10.1145/2095667.2095683}, 
month = {09}
}
@article{Peltola:2007dy, 
year = {2007}, 
rating = {0}, 
title = {{Synthesis of Hand Clapping Sounds}}, 
author = {Peltola, Leevi and Erkut, Cumhur and Cook, Perry R. and Välimäki, Vesa}, 
journal = {IEEE Transactions on Audio Speech and Language Processing}, 
issn = {1558-7916}, 
doi = {10.1109/tasl.2006.885924}, 
abstract = {{We present two physics-based analysis, synthesis, and control systems for synthesizing hand clapping sounds. They both rely on the separation of the sound synthesis and event generation, and both are capable of producing individual hand-claps, or mimicking the asynchronous/synchronized applause of a group of clappers. The synthesis models consist of resonator filters, whose coefficients are derived from experimental measurements. The difference between these systems is mainly in the statistical event generation. While the first system allows an efficient parametric synthesis of large audiences, as well as flocking and synchronization by simple rules, the second one provides parametric extensions for synthesis of various clapping styles and enhanced control strategies. The synthesis and the control models of both systems are implemented as software running in real time at the audio sample rate, and they are available for download at at http://ccrma-www.stanford.edu/software/stk and http://www.acoustics.hut.fi/go/clapd.}}, 
pages = {1021--1029}, 
number = {3}, 
volume = {15}, 
keywords = {}, 
month = {03}
}
@inproceedings{Jylha:2009gq, 
year = {2009}, 
rating = {0}, 
author = {Jylhä, Antti and Erkut, Cumhur}, 
title = {{A hand clap interface for sonic interaction with the computer}}, 
isbn = {9781605582474}, 
doi = {10.1145/1520340.1520452}, 
url = {http://dl.acm.org/citation.cfm?id=1520452}, 
abstract = {{We present a hand clapping interface for sonic interaction with the computer. The current implementation has been built on the Pure Data (PD) software. The interface makes use of the cyclic nature of hand clapping and recognition of the clap type, and enables interactive control over different applications. Three prototype applications for the interface are presented: a virtual crowd of clappers, controlling the tempo of music, and a simple sampler. Preliminary tests indicate that rather than having total control via the interface, the user negotiates with the computer to control the tempo.}}, 
urldate = {0}, 
pages = {3175--3180}, 
series = {Conf. Human Factors in Computing Systems}, 
keywords = {}
}
@inproceedings{Conte:E7CGxjBi, 
year = {2015}, 
rating = {0}, 
keywords = {one}, 
author = {Erkut, Cumhur and Rajala-Erkut, Anu}, 
title = {{Beyond Command \& Control: Sketching Embodied Interaction}}, 
isbn = {9781450331463}, 
doi = {10.1145/2702613.2732855}, 
url = {http://dl.acm.org/citation.cfm?doid=2702613.2732855}, 
abstract = {{We present an approach for teaching and designing embodied interaction in collaboration with a contemporary dance choreographer. Our approach is based on the felt qualities of movement, and provides a shared experience, vocabulary for self-expression, and appreciation for movement as a design material for interaction design practitioners. We present a workshop, where after movement sessions, interactive sketches were generated and implemented by motion tracking. Subsequently, we have investigated whether or not these activities guided the participants from the prevailing notion of command/control in embodied interaction towards experiences related to the felt qualities of movement. While in idea generation, our approach has provided a better foundation for participants, compared to the approaches that focus only on technologies, this effect wore off and final implementations focused on command \& control. We currently experiment with new tools and techniques, integrating material interactions into the process.}}, 
urldate = {0}, 
pages = {1681--1686}, 
series = {the 33rd Annual ACM Conference Extended Abstracts}, 
note = {\#one gourd bigger than the other}
}
@inproceedings{Tolonen99:ICMC, 
year = {1999}, 
rating = {0}, 
keywords = {physical,Sound}, 
author = {Tolonen, Tero and Erkut, Cumhur and Välimäki, Vesa and Karjalainen, Matti}, 
title = {{Simulation of plucked strings exhibiting tension modulation driving force}}, 
url = {http://www.acoustics.hut.fi/\textbackslashtextasciitildemak/PUB/ICMC1999Tolonen.pdf}, 
abstract = {{ABSTRACT Recently, a nonlinear discrete-time model that simulates a vibrating string exhibiting tension modulation has been presented. This paper elaborates the previous model by taking into account two phenomena: 1) coupling of the tension modulation force ...}}, 
urldate = {0}, 
series = {Intl. Computer Music Conf.}, 
note = {\#physical modeling \#Sound Synthesis}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Tolonen-1999.pdf}
}
@inproceedings{Erkut:2013vw, 
year = {2013}, 
rating = {0}, 
keywords = {AAU:CPH,agar,game-audio}, 
author = {Erkut, Cumhur and Hacıhabiboğlu, Hüseyin}, 
title = {{Rhythm-Action Games: The Sonic Interaction Perspective}}, 
url = {http://www.aes.org/e-lib/browse.cfm?elib=16660}, 
urldate = {0}, 
pages = {1 9}, 
series = {Audio for Games}, 
note = {2022-12-31 Ping for eliciting }, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2013.pdf}
}
@article{Rabenstein:2007ug, 
year = {2007}, 
rating = {0}, 
title = {{Blocked-Based Physical Modeling for Digital Sound Synthesis}}, 
author = {Rabenstein, Rudolf and Petrausch, Stefan and Sarti, Augusto and Sanctis, Giovanni De and Erkut, Cumhur and Karjalainen, Matti}, 
journal = {IEEE Signal Processing Magazine}, 
issn = {1053-5888}, 
doi = {10.1109/msp.2007.323263}, 
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=4117928}, 
abstract = {{Block-based physical modeling is a methodology for modeling physical systems with different subsystems. It is an important concept for the physical modeling of real or virtual musical instruments where different components may be modeled according to different paradigms. Connecting systems of diverse nature in the discrete-time domain requires a common interconnection strategy. This contribution presents suitable interconnection strategies that incorporate a wide range of modeling blocks and considers the automatic implementation of block-based structures. Software environments are presented, which allow to build complex sound synthesis systems without burdening the user with problems of block compatibility.}}, 
pages = {42--54}, 
number = {2}, 
volume = {24}, 
language = {English}, 
note = {gary: resonators mistuned for DAFx?}, 
keywords = {}
}
@article{Erkut:0a22, 
year = {2018}, 
title = {{Mobile AR In and Out: Towards Delay-Based Modeling of Acoustic Scenes}}, 
author = {Erkut, Cumhur and Holfelt, Jonas and Serafin, Stefania}, 
journal = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1109/vr.2018.8446230}, 
abstract = {{We have previously presented an augmented reality (AR) audio application, where scattering delay networks efficiently generate and organize a reverberator, based on room geometry scanned by an AR device. The application allowed for real-time processing and updating of reflection path geometry and provided a proof-of-concept for plausible audio-spatial registration of a virtual object in real environments. Here we present our ongoing work that aims to extend the simulation to outdoor scenes by using the Waveguide Web, instead of the original formulation with the Scattering Delay Networks. The current implementation is computationally more demanding, but has a potential to provide more accurate second-order reflections, and therefore, better registering of audio-visual AR scenes.}}, 
pages = {1--2}, 
volume = {00}, 
keywords = {}
}
@article{Karjalainen:2004hp, 
year = {2004}, 
rating = {5}, 
keywords = {alma,asp04,asp08-further,Audio,d9,digital,fdtd,hybrid,Model,modeling,models,physical,processing,scattering,schema,signal,Sound,sound-source,structures,waveguides,wg}, 
title = {{Digital Waveguides versus Finite Difference Structures: Equivalence and Mixed Modeling}}, 
author = {Karjalainen, Matti and Erkut, Cumhur}, 
journal = {EURASIP Journal on Advances in Signal Processing}, 
doi = {10.1155/s1110865704401176}, 
url = {http://dl.acm.org/citation.cfm?id=1289420}, 
abstract = {{Digital waveguides and finite difference time domain schemes have been used in physical modeling of spatially distributed systems. Both of them are known to provide exact modeling of ideal one-dimensional (1D) band-limited wave propagation, and both of them can be composed to approximate two-dimensional (2D) and three-dimensional (3D) mesh structures. Their equal capabilities in physical modeling have been shown for special cases and have been assumed to cover generalized cases as well. The ability to form mixed models by joining substructures of both classes through converter elements has been proposed recently. In this paper, we formulate a general digital signal processing (DSP)-oriented framework where the functional equivalence of these two approaches is systematically elaborated and the conditions of building mixed models are studied. An example of mixed modeling of a 2D waveguide is presented.}}, 
pages = {561060}, 
number = {7}, 
volume = {2004}, 
language = {English}, 
note = {\#alma \#asp04 \#asp08-further \#Audio \#d9 \#digital \#fdtd \#hybrid \#Model \#modeling \#models \#physical \#processing \#scattering \#schema \#signal \#Sound \#sound-source \#structures \#waveguides \#wg}
}
@article{Maculewicz:2015a22, 
year = {2015}, 
title = {{The Effects of Ecological Auditory Feedback on Rhythmic Walking Interaction}}, 
author = {Maculewicz, Justyna and Jylha, Antti and Serafin, Stefania and Erkut, Cumhur}, 
journal = {IEEE MultiMedia}, 
issn = {1070-986X}, 
doi = {10.1109/mmul.2015.17}, 
url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030181}, 
abstract = {{The authors present a system capable of rhythmic walking interactions using auditory display. The feedback is based on footstep sounds and follows either detected footsteps or suggests a tempo, which is either constant or adapts to the walker. The auditory display contains simple sinusoidal tones or ecological, physically based synthetic walking sounds. In the tempo-following experiment, the authors investigate the different interaction modes (step versus constant or adaptive tempo) and auditory feedback (sinusoidal tones versus ecological walking sounds) with respect to their effect on walking tempo. They calculate the mean square error (MSE) between the performed and target tempo and the stability of the performed tempo. The results indicate that the MSE with ecological sounds is better than or comparable to that with the sinusoidal tones, yet ecological sounds are considered more natural. Allowing deviations from the cues in the adaptive conditions results in a tempo that's still stable but closer to the natural walking pace of the subjects. These results have implications on the design of interactive entertainment or rehabilitation.}}, 
pages = {24--31}, 
number = {1}, 
volume = {22}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Maculewicz-2015.pdf}
}
@inproceedings{Summers:2015wd, 
year = {2015}, 
rating = {0}, 
author = {Summers, Chanel and Lympouridis, Vangelis and Erkut, Cumhur}, 
title = {{Sonic Interaction Design for Virtual and Augmented Reality Environments}}, 
isbn = {978-1-4799-1969-7}, 
doi = {10.1109/sive.2015.7361290}, 
abstract = {{Sonic Interaction Design (SID) primarily focuses on enhancing the quality of an interactive experience for the user by utilizing explicit techniques and defining advanced computational objects. While the diverse methods in SID are being documented, we argue for a need to refocus on the experiential, embodied, contextual, playful, and holistic qualities of sonic interactions. In this paper, we discuss specific SID techniques that can be used to advance story and gameplay in virtual and augmented environments. We shortly introduce the audio technologies used in virtual reality, and complement these with the practical examples about their (mis)use. We then illustrate the SID in the augmented environment of Leviathan, featured in Intel's 2014 CES keynote. We discuss methods such as defining characters through sound, embracing and critically using ambiguity, and coordinating sound and music. Through the notion of multimodal listening we provide guidelines to sonic interaction designers, so that they not only make their audience to listen in to digital content, but also listen up, out, through, and around.}}, 
urldate = {0}, 
pages = {37--42}, 
series = {2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments (SIVE)}, 
keywords = {}
}
@article{Baldwin:2018a22, 
year = {2018}, 
title = {{Towards the Design and Evaluation of Delay-based Modeling of Acoustic Scenes in Mobile Augmented Reality}}, 
author = {Baldwin, Alex and Serafin, Stefania and Erkut, Cumhur}, 
journal = {2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE)}, 
doi = {10.1109/sive.2018.8577129}, 
abstract = {{ScatAR is an augmented reality (AR) audio application, where scattering delay networks (SDNs) efficiently generate and organize a reverberator based on room geometry scanned by an AR device. Here we present a perceptual evaluation of the application in terms of auditory object presence. Specifically, we investigate the personal preferences on the auditory registration of a sounding object (a drone transmitting speech) in a room in anechoic versus artificial reverberation conditions. The results indicate a marginal preference of the reverberation, but much less than what we have anticipated. We discuss possible reasons for this, and set to compare our SDN implementation with a Waveguide Web (WGW) simulation in AR. While the WGWs are computationally more demanding, they have a potential to provide more accurate second-order reflections, and therefore, better registering of audio-visual AR scenes.}}, 
pages = {1--5}, 
keywords = {}
}
@article{Baldwin:2017f31, 
year = {2017}, 
rating = {0}, 
title = {{ScatAR: a mobile augmented reality application that uses scattering delay networks for room acoustic synthesis}}, 
author = {Baldwin, Alex and Serafin, Stefania and Erkut, Cumhur}, 
journal = {Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology}, 
doi = {10.1145/3139131.3141201}, 
url = {https://dl.acm.org/citation.cfm?doid=3139131.3141201}, 
abstract = {{We present an augmented reality (AR) audio application where scattering delay networks efficiently generate and organize a reverberator, based on room geometry scanned by an AR device. The application allows for real-time processing and updating of reflection path geometry. It provides a proof-of-concept for plausible audio-spatial registration of a virtual object in a real environment, but further tests are needed in perceptual evaluation.}}, 
pages = {73--74}, 
keywords = {}
}
@inproceedings{Andersson.2019, 
year = {2019}, 
author = {Andersson, Nikolaj and Erkut, Cumhur and Serafin, Stefania}, 
title = {{Immersive Audio Programming in a Virtual Reality Sandbox}}, 
booktitle = {Proc. AES Conf. Immersive and Interactive Audio}, 
url = {http://www.aes.org/e-lib/browse.cfm?elib=20443}, 
abstract = {{Immersive sandboxes for audio-visual content creation in Virtual Reality (VR) are becoming widely available, thanks to VR distribution platforms such as Steam VR. Some of these sandboxes are specially build to host VirtualReality Musical Instruments (VRMIs) In this paper, after describing the MuX, a VRMI-hosting sandbox, and its components, we present new elements developed for the environment. We focus on lumped and distributed physically-inspired models for sound synthesis. A simple interface was developed to control the physical models with gestures, expanding the interaction possibilities within MuX. A preliminary evaluation of the sandbox shows that as the number and complexity of the components increase, it becomes important to provide to the users ready-made machines instead of allowing them to build everything from scratch.}}, 
keywords = {}, 
month = {3}
}
@article{Serafin:2016kh, 
year = {2016}, 
month = {9}, 
rating = {0}, 
title = {{Virtual Reality Musical Instruments: State of the Art, Design Principles, and Future Directions}}, 
author = {Serafin*, Stefania and Erkut*, Cumhur and Kojs†, Juraj and Nilsson*, Niels C. and Nordahl*, Rolf}, 
journal = {Computer Music Journal}, 
issn = {0148-9267}, 
doi = {10.1162/comj\_a\_00372}, 
abstract = {{The rapid development and availability of low-cost technologies have created a wide interest in virtual reality. In the field of computer music, the term “virtual musical instruments” has been used for a long time to describe software simulations, extensions of existing musical instruments, and ways to control them with new interfaces for musical expression. Virtual reality musical instruments (VRMIs) that include a simulated visual component delivered via a head-mounted display or other forms of immersive visualization have not yet received much attention. In this article, we present a field overview of VRMIs from the viewpoint of the performer. We propose nine design guidelines, describe evaluation methods, analyze case studies, and consider future challenges.}}, 
pages = {22--40}, 
number = {3}, 
volume = {40}, 
language = {English}, 
keywords = {}
}
@inproceedings{Erkut.2018ytr, 
year = {2018}, 
author = {Erkut, Cumhur and Dahl, Sofia}, 
title = {{Incorporating Virtual Reality in an Embodied Interaction Course}}, 
isbn = {9781450365048}, 
doi = {10.1145/3212721.3212884}, 
abstract = {{Engagement with virtual reality (VR) through movement is becoming increasingly important. Therefore, the VR developers should improve their bodily skills and learn how to use the movement as design material. In addition, first person accounts of the development and experience are necessary. We explore the education space in VR with attention to the first-person experiences, movement data and code, and present an approach for teaching and designing VR-based embodied interaction.}}, 
keywords = {}
}
@article{Erkut.2019.Journal of Somaesthetics, 
year = {2019}, 
title = {{Incorporating Virtual Reality with Experiential Somaesthetics in an Embodied Interaction Course}}, 
author = {Erkut, Cumhur and Dahl, Sofia}, 
journal = {Journal of Somaesthetics}, 
url = {https://somaesthetics.aau.dk/index.php/JOS/article/view/2399/2507}, 
abstract = {{Engagement  with  virtual  reality  (VR)  through  movement  is  becoming  increasingly  important.  Therefore,  VR  developers  should  improve  their  bodily  skills  and  learn  how  to  use  movement  as  design  material.  To  do  so,  first-person  accounts  of  the  development  and  experience  are  necessary.  Since  these  qualities  are well addressed in experiential somaesthetics, we explore the education space in VR, with attention to the first-person experiences, movement data, and code. We present  an  approach  for  teaching  and  designing  VR-based  embodied  interaction  and  describe  simple  projects  implemented  by  the  participants.  The  evaluation  of  projects  indicates  that  the  concepts,  practices,  and  perspectives  of  embodied  interaction  were  attained  in  VR.  Our  reflections  contribute  to  the  literature  on  movement-based interaction education in VR, and its evaluation and validation by first-person accounts, in addition to the data and program code produced.  }}, 
pages = {25--39}, 
number = {2}, 
volume = {4}, 
keywords = {}, 
month = {3}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2019.pdf}
}
@inproceedings{Erkut.2017, 
year = {2017}, 
author = {Erkut, Cumhur and Fehr, Jonas}, 
title = {{Structuring Design and Evaluation of an Interactive Installation Through Swarms of Light Rays with Human-Artifact Model}}, 
isbn = {9783319558332}, 
doi = {10.1007/978-3-319-55834-9\_5}, 
abstract = {{We present the design and evaluation of an interactive installation to be explored by movement and sound under Human-Activity Model. In the installation, movement qualities that are extracted from the motion tracking data excite a dynamical system (a synthetic flock of agents), which responds to the movement qualities and indirectly controls the visual and sonic feedback of the interface. In other words, the relationship between gesture and sound are mediated by synthetic swarms of light rays. A test session was conducted with eleven subjects, who were asked to investigate the installation and to fill out a questionnaire afterwards. In this paper, we report our preliminary work on the analysis of the tensions of interaction with the installation under the Human-Artifact Model. Our results indicate exploration and discovery as the main motives of the interaction. This is different than utilitarian HCI artifacts, where the instrumental aspects are typically in the foreground.}}, 
pages = {39--46}, 
keywords = {}, 
month = {5}
}
@article{Hussain.2019, 
year = {2019}, 
title = {{Evaluating movement qualities with visual feedback for real-time motion capture}}, 
author = {Hussain, Aishah and Modekjaer, Camilla and Austad, Nicoline Warming and Dahl, Sofia and Erkut, Cumhur}, 
doi = {10.1145/3347122.3347123}, 
pages = {1--9}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Hussain-2019.pdf}
}
@article{Pajala-Assefa.2019, 
year = {2019}, 
title = {{A Study of Movement-Sound within Extended Reality}}, 
author = {Pajala-Assefa, Hanna and Erkut, Cumhur}, 
doi = {10.1145/3347122.3359604}, 
pages = {1--4}, 
keywords = {}
}

@inproceedings{Kaspersen.2020l6v,
  year =	 2020,
  author =	 {Kaspersen, Esbern and Górny, Dawid and Erkut, Cumhur and Palamas, George},
  title =	 {Generative Choreographies: The Performance Dramaturgy of the Machine},
  isbn =	 9789897584022,
  doi =		 {10.5220/0008990403190326},
  abstract =	 {This paper presents an approach for a full body interactive environment in which performers manipulate virtual actors in order to augment a live performance. The aim of this research is to explore the role of generative animation to serve an interactive performance, as a dramaturgical approach in new media. The proposed system consists of three machine learning modules encoding a human’s movement into generative dance, performed by an avatar in a virtual world. First, we provide a detailed description of the technical aspects of the system. Afterwards, we discuss the critical aspects summarized on the basis of dance practice and new media technologies. In the process of this discussion, we emphasize the ability of the system to conform with a movement style and communicate choreographic semiotics, affording artists with new ways of engagement with their audiences.},
  pages =	 {319--326},
  series =	 {Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  booktitle =	 {Proc. Intl. Joint Conf. Computer Vision, Imaging and Computer Graphics Theory and Applications (GRAP)}
}
  
@article{Karjalainen.2004.The Journal of the Acoustical Society of America, 
year = {2004}, 
title = {{Interconnecting digital waveguides and finite difference structures: Recent advances}}, 
author = {Karjalainen, Matti and Erkut, Cumhur}, 
journal = {The Journal of the Acoustical Society of America}, 
issn = {0001-4966}, 
doi = {10.1121/1.4785230}, 
pages = {2562--2562}, 
number = {4}, 
volume = {116}, 
keywords = {}
}
@article{Erkut.2008.The Journal of the Acoustical Society of America, 
year = {2008}, 
title = {{Interacting with virtual musical instruments at the junction nodes}}, 
author = {Erkut, Cumhur and Jylhä, Antti and Karjalainen, Matti}, 
journal = {The Journal of the Acoustical Society of America}, 
issn = {0001-4966}, 
doi = {10.1121/1.2934447}, 
pages = {3521--3521}, 
number = {5}, 
volume = {123}, 
keywords = {}
}
@article{Serafin.2020.Journal of New Music Research, 
year = {2020}, 
title = {{Reflections from five years of Sonic Interactions in Virtual Environments workshops}}, 
author = {Serafin, Stefania and Avanzini, Federico and Goetzen, Amalia De and Erkut, Cumhur and Geronazzo, Michele and Grani, Francesco and Nilsson, Niels Christian and Nordahl, Rolf}, 
journal = {Journal of New Music Research}, 
issn = {0929-8215}, 
doi = {10.1080/09298215.2019.1708413}, 
abstract = {{For the past five years, the authors have been running at the IEEE Virtual Reality Conference a Workshop called Sonic Interactions in Virtual Environments (SIVE). The main goal of the workshop series has been to increase among the virtual reality community awareness of the importance of sonic elements when designing multimodal and immersive virtual environments. Starting from this experience, this paper presents a survey of the main active research topics related to sound in virtual and augmented reality (VR/AR), ranging from basic research in spatial audio rendering and sonic interaction design to applications in interactive environments for training, health, rehabilitation, entertainment, and art. Looking at the different research topics emerging from laboratories worldwide, the paper discusses how different research communities can collaborate and benefit from each other in order to increase sound awareness in VR and AR.}}, 
journaltitle = {Journal of New Music Research}, 
pages = {24--34}, 
number = {1}, 
volume = {49}, 
keywords = {}
}
@inproceedings{Erkut02:AES22, 
year = {2002}, 
rating = {0}, 
keywords = {alma,differences,finite,modeling,physical,ropp,Sound}, 
author = {Erkut, Cumhur and Karjalainen, Matti}, 
title = {{Virtual strings based on a 1-D FDTD Waveguide Model: Stability, Losses, and travelling waves}}, 
url = {http://users.spa.aalto.fi/mak/PUB/AES22\_Erkut.pdf}, 
abstract = {{The one-dimensional digital waveguide structures based on finite difference time domain (FDTD) formulations provide aflexible approach for real-time sound synthesis of simple one-dimensional (1-D) structures, such as a vibrating string. Thispaper summarizes the basic 1-D FDTD waveguide theory, carries out the stability analysis of the model, and presents asufficient condition for the stability. The simulation of frequency-independent losses has also been covered. The formationof the traveling waves and initialization of the 1-D FDTD waveguides are investigated. The methods shown in the papermay be used to interconnect the 1-D FDTD waveguides to other model-based sound synthesis structures, such as digitalwaveguides that are based on the traveling wave solution of the wave equation.}}, 
urldate = {0}, 
pages = {317 323}, 
note = {\#alma \#differences \#finite \#modeling \#physical \#physical modeling \#ropp \#Sound Synthesis}, 
month = {06}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Erkut-2002_1.pdf}
}
@article{Baldwin.2019.SMC Nordic Conf., 
year = {2019}, 
title = {{Efficient Rendering and Perception of Acoustical Environments in Augmented Reality Audio}}, 
author = {Baldwin, Alex and Holfelt, Jonas and Erkut, Cumhur}, 
journal = {SMC Nordic Conf.}, 
url = {http://smcsweden.se/}, 
journaltitle = {SMC Nordic Conf.}, 
keywords = {}
}
@article{Serafin.2016.Computer Music Journal, 
year = {2016}, 
title = {{Virtual Reality Musical Instruments: State of the Art, Design Principles, and Future Directions}}, 
author = {Serafin, Stefania and Erkut, Cumhur and Kojs, Juraj and Nilsson, Niels and Nordahl, Rolf}, 
journal = {Computer Music Journal}, 
issn = {0148-9267}, 
doi = {10.1162/comj\_a\_00372}, 
abstract = {{The rapid development and availability of low-cost technologies have created a wide interest in virtual reality. In the field of computer music, the term “virtual musical instruments” has been used for a long time to describe software simulations, extensions of existing musical instruments, and ways to control them with new interfaces for musical expression. Virtual reality musical instruments (VRMIs) that include a simulated visual component delivered via a head-mounted display or other forms of immersive visualization have not yet received much attention. In this article, we present a field overview of VRMIs from the viewpoint of the performer. We propose nine design guidelines, describe evaluation methods, analyze case studies, and consider future challenges.}}, 
pages = {22--40}, 
number = {3}, 
volume = {40}, 
keywords = {}
}
@article{Kaspersen.2020, 
year = {2020}, 
title = {{Hydranet: A Real-Time Waveform Separation Network}}, 
author = {Kaspersen, Esbern Torgard and Kounalakis, Tsampikos and Erkut, Cumhur}, 
journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
doi = {10.1109/icassp40776.2020.9053357}, 
abstract = {{Real-time source separation has become increasingly important, as more and more applications, such as voice recognition and voice commands, require clean audio input in noisy environments. Recent developments in deep learning have allowed models to directly exploit the waveform of the audio, making real-time separation achievable. In this paper, we propose a 1-D convolutional U-Net structure to separate waveform input. This structure incorporates recurrent layers, to exploit longer temporal connections in the audio signal. Our proposed network architecture is also benefiting from the addition of an extra output channel, measuring the distortion of the other output channels. Our proposed methodology is experimentally shown to yield state-of-the-art results, using only 0.76 seconds of input audio.}}, 
pages = {4327--4331}, 
volume = {00}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Kaspersen-2020_1.pdf}
}
@inproceedings{Eklund.2020, 
year = {2019}, 
author = {Eklund, Rasmus and Erkut, Cumhur}, 
title = {{A Positional Infrared Tracking System Using Non-individualised HRTFs to Simulate a Loudspeaker Setup and Its Influence on Externalisation of Music}}, 
booktitle = {Proc. EAI Intl. Conf. ArtsIT}, 
isbn = {9783030532932}, 
doi = {10.1007/978-3-030-53294-9\_11}, 
abstract = {{Many artists produce and mix their virtual reality, game, or screen media audio productions only with headphones, but deploy them to stereo or multi-channel loudspeaker setups. Because of the acoustical and perceptual differences, listening on headphones might sound very different compared to loudspeakers, including the perception of sound sources inside the head (externalisation problem). Nevertheless, by using Head Related Transfer Functions (HRTFs) and accurate movement tracking, it is possible to simulate a loudspeaker setup with proper externalisation. In this paper, an infrared-based positional tracking system with non-individualised HRTFs to simulate a loudspeaker setup is conceptualised, designed and implemented. The system can track the user with six degrees of freedom (6-DOF); an improvement over current commercial systems that only use 3-DOF tracking. The system was evaluated on 20 participants to see if the additional DOF increased the degree of externalisation. While tracking increased the externalisation in general, there was no significant difference between 3-DOF and 6-DOF. Another test indicated that positional movement coupled with positional tracking may have a greater effect on externalisation compared to positional movement coupled with only head movement tracking. Comparisons between these results and previous studies are discussed and improvements for future experiments are proposed.}}, 
pages = {158--177}, 
keywords = {}
}
@article{Alonso.2021, 
year = {2021}, 
title = {{Latent Space Explorations of Singing Voice Synthesis using DDSP}}, 
author = {Alonso, Juan and Erkut, Cumhur}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2103.07197}, 
eprint = {2103.07197}, 
url = {https://juanalonso.github.io/DDSP-singing-experiments}, 
abstract = {{Machine learning based singing voice models require large datasets and lengthy training times. In this work we present a lightweight architecture, based on the Differentiable Digital Signal Processing (DDSP) library, that is able to output song-like utterances conditioned only on pitch and amplitude, after twelve hours of training using small datasets of unprocessed audio. The results are promising, as both the melody and the singer's voice are recognizable. In addition, we present two zero-configuration tools to train new models and experiment with them. Currently we are exploring the latent space representation, which is included in the DDSP library, but not in the original DDSP examples. Our results indicate that the latent space improves both the identification of the singer as well as the comprehension of the lyrics. Our code is available at https://github.com/juanalonso/DDSP-singing-experiments with links to the zero-configuration notebooks, and our sound examples are at https://juanalonso.github.io/DDSP-singing-experiments/ .}}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Alonso-2021.pdf}
}
@article{Bigoni.2020, 
year = {2020}, 
title = {{DogDog}}, 
author = {Bigoni, Francesco and Erkut, Cumhur}, 
journal = {Proceedings of the 7th International Conference on Movement and Computing}, 
doi = {10.1145/3401956.3404242}, 
url = {https://vimeo.com/435553927}, 
abstract = {{Improvisation is embodied thought and expression. This paper outlines strategies and tactics to design expressive musical interfaces for improvisers. Some of these strategies are explored through a case study: a non-tactile hand-arm movement interface controlling a granular synthesizer (DogDog), based on high-level movement descriptors. The research through design and performance experience indicates that movement quality descriptors are inherently scalable from hand-arm movements to full body interaction, and that a textural approach to motion tracking fits well the morphing sonic masses generated through granular sound synthesis.}}, 
pages = {1--4}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Bigoni-2020.pdf}
}
@inproceedings{Laurson.1999, 
year = {1999}, 
rating = {0}, 
author = {Laurson, Mikael and Hiipakka, Jarmo and Erkut, Cumhur and Karjalainen, Matti and Välimäki, Vesa and Kuuskankare, Mika}, 
title = {{From Expressive Notation to Model-Based Sound Synthesis: a Case Study of the Acoustic Guitar}}, 
url = {https://quod.lib.umich.edu/i/icmc/bbp2372.1999.323/1}, 
abstract = {{The focus of this work is in modeling the unique sound and the playing practices of the acoustic guitar. The results can be applied to other plucked string instruments too. A new extended notation package is used to produce expressive control information. This tool allows the user to add to the input score instrumental expressions and tempo functions. The system includes also a rule formalism that permits further fine tuning of the computer-generated performance. A real-time synthesis engine has been developed based on earlier results in digital waveguide modeling. We also describe an analysis of vibrato in acoustic guitar tones, which provides control information for realistic synthesis.}}, 
urldate = {2021-04-29}, 
pages = {1 4}, 
address = {Beijing, PRC}, 
note = {From Expressive Notation to Model-Based Sound Synthesis: a Case Study of the Acoustic Guitar Laurson, Mikael; Hiipakka, Jarmo; Erkut, Cumhur; Karjalainen, Matti; Vôlimôki, Vesa; Kuuskankare, Mika
Skip other details (including permanent urls, DOI, citation information)
Volume 1999, 1999
Permalink: http://hdl.handle.net/2027/spo.bbp2372.1999.323

See also http://lib.tkk.fi/Diss/2002/isbn9512261901/article4.pdf }, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Laurson-1999.pdf}
}
@article{Erkut.2009, 
year = {2009}, 
title = {{Recent advances in exploring self-induced sonic interactions in the context of performing arts}}, 
author = {Erkut, Cumhur and Jylhä, Antti and KorayTahiroglu and Ekman, Inger}, 
abstract = {{Erkut, Cumhur, Antti Jylhä, and I. Ekman. "Recent advances in exploring self-induced sonic interactions in the context of performing arts." Proceedings of the International Workshop on Haptic and Audio Interaction Design, Dresden, Germany. Vol. 29. 2009.}}, 
keywords = {}
}
@inproceedings{Ganis.2021, 
year = {2021}, 
author = {Ganis, Francesco and Knudesn, Erik Frej and Lyster, Søren V K and Otterbein, Robin and Südholt, David and Erkut, Cumhur}, 
title = {{Real-time Timbre Transfer and Sound Synthesis using DDSP}}, 
booktitle = {Proc. Sound and Music Computing Conf.}, 
doi = {10.5281/zenodo.5043235}, 
abstract = {{Neural audio synthesis is an actively researched topic, having yielded a wide range of techniques that leverages machine learning architectures. Google Magenta elaborated a novel approach called Differential Digital Signal Processing (DDSP) that incorporates deep neural networks with preconditioned digital signal processing techniques, reaching state-of-the-art results especially in timbre transfer applications. However, most of these techniques, including the DDSP, are generally not applicable in real-time constraints, making them ineligible in a musical workflow. In this paper, we present a real-time implementation of the DDSP library embedded in a virtual synthesizer as a plug-in that can be used in a Digital Audio Workstation. We focused on timbre transfer from learned representations of real instruments to arbitrary sound inputs as well as controlling these models by MIDI. Furthermore, we developed a GUI for intuitive high-level controls which can be used for post-processing and manipulating the parameters estimated by the neural network. We have conducted a user experience test with seven participants online. The results indicated that our users found the interface appealing, easy to understand, and worth exploring further. At the same time, we have identified issues in the timbre transfer quality, in some components we did not implement, and in installation and distribution of our plugin. The next iteration of our design will address these issues. Our real-time MATLAB and JUCE implementations are available at https://github.com/SMC704/juce-ddsp and https://github.com/SMC704/matlab-ddsp , respectively.}}, 
pages = {175--182}, 
series = {arXiv}, 
keywords = {}
}
@article{Jylhä.2012, 
year = {2012}, 
title = {{Rhythmic walking interactions with auditory feedback}}, 
author = {Jylhä, Antti and Serafin, Stefania and Erkut, Cumhur}, 
journal = {Proceedings of the 7th Audio Mostly Conference on A Conference on Interaction with Sound - AM '12}, 
doi = {10.1145/2371456.2371467}, 
abstract = {{Walking is a natural rhythmic activity that has become of interest as a means of interacting with software systems such as computer games. Therefore, designing multimodal walking interactions calls for further examination. This exploratory study presents a system capable of different kinds of interactions based on varying the temporal characteristics of the output, using the sound of human walking as the input. The system either provides a direct synthesis of a walking sound based on the detected amplitude envelope of the user's footstep sounds, or provides a continuous synthetic walking sound as a stimulus for the walking human, either with a fixed tempo or a tempo adapting to the human gait. In a pilot experiment, the different interaction modes are studied with respect to their effect on the walking tempo and the experience of the subjects. The results tentatively outline different user profiles in interacting with such a system.}}, 
pages = {68--75}, 
keywords = {}
}
@article{Erkutk0v, 
year = {2006}, 
rating = {0}, 
title = {{Discrete-time modelling of musical instruments}}, 
author = {Erkut, Cumhur and Välimäki, Vesa and Karjalainen, Matti and Pakarinen, Jyri}, 
journal = {Reports on Progress in Physics}, 
issn = {0034-4885}, 
doi = {10.1088/0034-4885/69/1/r01}, 
abstract = {{This article describes physical modelling techniques that can be used for simulating musical instruments. The methods are closely related to digital signal processing. They discretize the system with respect to time, because the aim is to run the simulation using a computer. The physics-based modelling methods can be classified as mass–spring, modal, wave digital, finite difference, digital waveguide and source–filter models. We present the basic theory and a discussion on possible extensions for each modelling technique. For some methods, a simple model example is chosen from the existing literature demonstrating a typical use of the method. For instance, in the case of the digital waveguide modelling technique a vibrating string model is discussed, and in the case of the wave digital filter technique we present a classical piano hammer model. We tackle some nonlinear and time-varying models and include new results on the digital waveguide modelling of a nonlinear string. Current trends and future directions in physical modelling of musical instruments are discussed.}}, 
pages = {1–78}, 
number = {1}, 
volume = {69}, 
language = {English}, 
keywords = {}, 
month = {01}
}
@patent{Salmi.2009, 
year = {2009}, 
title = {{System for sports activity}}, 
author = {Salmi, Timo and Salmi, Tomi and Jylhä, Antti and Välimäki, Vesa and Erkut, Cumhur}, 
url = {https://patents.google.com/patent/EP2205330A1}, 
abstract = {{A system for a sports activity, which system is adapted to detect potential game contacts that include contacts between games equipment (1) and a games object (2) and/or contacts between a games object (2) and a target surface (5), and the system comprises sensor means (3a, 3b) adapted to detect vibrations caused by potential game contacts and to convert these vibrations into sensor signals. The system is adapted to - define the value of the sensor signal at several consecutive discrete time instants, - define for a sensor signal section within a time frame k that contains N sensor signal values an energy value quantity E[k] that is related to the energy of the sensor signal section, - repeat the above step of defining the energy value quantity of the sensor signal section for several consecutive time frames, and - detect a potential game contact by utilizing a detection function D that is obtained by a linear combination of energy value quantities of sensor signal sections contained in consecutive time frames by using the formula (formula), wherein K is the number of energy value quantities used in calculation and an integer equal to or greater than two, and ci is a weighting coefficient for the energy value quantity E[k-i], whereby the detection of a potential game contact in the time frame k is based on comparing the value D[k] of the detection function D corresponding to the time frame k is compared with a threshold value.}}, 
urldate = {2022-7-21}, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Salmi-2009.pdf}
}
@article{10.1109/taslp.2022.3223257, 
year = {2022}, 
title = {{Pruning Deep Neural Network Models of Guitar Distortion Effects}}, 
author = {Sudholt, David and Wright, Alec and Erkut, Cumhur and Välimäki, Vesa}, 
journal = {IEEE/ACM Transactions on Audio, Speech and Language Processing}, 
issn = {2329-9290}, 
doi = {10.1109/taslp.2022.3223257}, 
url = {https://github.com/dsuedholt/PrunedGuitarVA}, 
abstract = {{Deep neural networks have been successfully used in the task of black-box modeling of analog audio effects such as distortion. Improving the processing speed and memory requirements of the inference step is desirable to allow such models to be used on a wide range of hardware and concurrently with other software. In this paper, we propose a new application of recent advancements in neural network pruning methods to recurrent black-box models of distortion effects using a Long Short-Term Memory architecture. We compare the efficacy of the method on four different datasets; one distortion pedal and three vacuum tube amplifiers. Iterative magnitude pruning allows us to remove over 99 of parameters from some models without a loss of accuracy. We evaluate the real-time performance of the pruned models and find that a 3x-4x speedup can be achieved, compared to an unpruned baseline. We show that training a larger model and then pruning it outperforms an unpruned model of equivalent hidden size. A listening test confirms that pruning does not degrade the perceived sound quality, but may even slightly improve it. The proposed techniques can be used to design computationally efficient deep neural networks for processing the sound of the electric guitar in real time.}}, 
pages = {256--264}, 
number = {99}, 
volume = {31}, 
keywords = {}
}
@article{10.1007/978-3-031-04021-4_7, 
year = {2022}, 
title = {{Sonic Interactions in Virtual Environments}}, 
author = {Olsen, Sophus Béneé and Høeg, Emil Rosenlund and Erkut, Cumhur}, 
journal = {Human–Computer Interaction Series}, 
issn = {1571-5035}, 
doi = {10.1007/978-3-031-04021-4\_7}, 
abstract = {{As the next generation of active video games (AVG) and virtual reality (VR) systems enter people’s lives, designers may wrongly aim for an experience decoupled from bodies. However, both AVG and VR clearly afford opportunities to bring experiences, technologies, and users’ physical and experiential bodies together, and to study and teach these open-ended relationships of enaction and meaning-making in the framework of embodied interaction. Without such a framework, an aesthetic pleasure, lasting satisfaction, and enjoyment would be impossible to achieve in designing sonic interactions in virtual environments (SIVE). In this chapter, we introduce this framework and focus on design exemplars that come from a soma design ideation workshop and balance rehabilitation. Within the field of physiotherapy, developing new conceptual interventions, with a more patient-centered approach, is still scarce but has huge potential for overcoming some of the challenges facing health care. We indicate how the tactics such as making space, subtle guidance, defamiliarization, and intimate correspondence have informed the exemplars, both in the workshop and also in our ongoing physiotherapy case. Implications for these tactics and design strategies for our design, as well as for general practitioners of SIVE are outlined.}}, 
pages = {219--235}, 
keywords = {}
}
@article{undefined, 
year = {2023}, 
title = {{Differentiable Allpass Filters for Phase Response Estimation and Automatic Signal Alignment}}, 
author = {Bargum, Anders R and Serafin, Stefania and Erkut, Cumhur and Parker, Julian D}, 
journal = {arXiv}, 
eprint = {2306.00860}, 
abstract = {{Virtual analog (VA) audio effects are increasingly based on neural networks and deep learning frameworks. Due to the underlying black-box methodology, a successful model will learn to approximate the data it is presented, including potential errors such as latency and audio dropouts as well as non-linear characteristics and frequency-dependent phase shifts produced by the hardware. The latter is of particular interest as the learned phase-response might cause unwanted audible artifacts when the effect is used for creative processing techniques such as dry-wet mixing or parallel compression. To overcome these artifacts we propose differentiable signal processing tools and deep optimization structures for automatically tuning all-pass filters to predict the phase response of different VA simulations, and align processed signals that are out of phase. The approaches are assessed using objective metrics while listening tests evaluate their ability to enhance the quality of parallel path processing techniques. Ultimately, an over-parameterized, BiasNet-based, all-pass model is proposed for the optimization problem under consideration, resulting in models that can estimate all-pass filter coefficients to align a dry signal with its affected, wet, equivalent.}}, 
keywords = {}
}
@article{10.48550/arxiv.2306.10886, 
year = {2023}, 
title = {{Vocal Timbre Effects with Differentiable Digital Signal Processing}}, 
author = {Südholt, David and Erkut, Cumhur}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2306.10886}, 
eprint = {2306.10886}, 
abstract = {{We explore two approaches to creatively altering vocal timbre using Differentiable Digital Signal Processing (DDSP). The first approach is inspired by classic cross-synthesis techniques. A pretrained DDSP decoder predicts a filter for a noise source and a harmonic distribution, based on pitch and loudness information extracted from the vocal input. Before synthesis, the harmonic distribution is modified by interpolating between the predicted distribution and the harmonics of the input. We provide a real-time implementation of this approach in the form of a Neutone model. In the second approach, autoencoder models are trained on datasets consisting of both vocal and instrument training data. To apply the effect, the trained autoencoder attempts to reconstruct the vocal input. We find that there is a desirable "sweet spot" during training, where the model has learned to reconstruct the phonetic content of the input vocals, but is still affected by the timbre of the instrument mixed into the training data. After further training, that effect disappears. A perceptual evaluation compares the two approaches. We find that the autoencoder in the second approach is able to reconstruct intelligible lyrical content without any explicit phonetic information provided during training.}}, 
keywords = {}
}
@article{10.48550/arxiv.2311.08104, 
year = {2023}, 
title = {{Reimagining Speech: A Scoping Review of Deep Learning-Powered Voice Conversion}}, 
author = {Bargum, Anders R and Serafin, Stefania and Erkut, Cumhur}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2311.08104}, 
eprint = {2311.08104}, 
abstract = {{Research on deep learning-powered voice conversion (VC) in speech-to-speech scenarios is getting increasingly popular. Although many of the works in the field of voice conversion share a common global pipeline, there is a considerable diversity in the underlying structures, methods, and neural sub-blocks used across research efforts. Thus, obtaining a comprehensive understanding of the reasons behind the choice of the different methods in the voice conversion pipeline can be challenging, and the actual hurdles in the proposed solutions are often unclear. To shed light on these aspects, this paper presents a scoping review that explores the use of deep learning in speech analysis, synthesis, and disentangled speech representation learning within modern voice conversion systems. We screened 621 publications from more than 38 different venues between the years 2017 and 2023, followed by an in-depth review of a final database consisting of 123 eligible studies. Based on the review, we summarise the most frequently used approaches to voice conversion based on deep learning and highlight common pitfalls within the community. Lastly, we condense the knowledge gathered, identify main challenges and provide recommendations for future research directions.}}, 
note = {240215: R8 comments }, 
keywords = {}, 
local-url = {file://localhost/Users/cer/bibliography/bibtex-pdfs/Bargum-2023.pdf}
}